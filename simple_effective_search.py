#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è APARU LLM
–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Tuple

class SimpleEffectiveSearch:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞"""
        
        # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
        self.knowledge_base = []
        
    def load_knowledge_base(self, kb_file: str = "database_Aparu/BZ.txt"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        
        print("üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...")
        
        # –ß–∏—Ç–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –±–∞–∑—É
        with open(kb_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü–∞—Ä—Å–∏–º –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã
        sections = content.split('- question:')
        
        for section in sections[1:]:
            lines = section.strip().split('\n')
            if len(lines) >= 2:
                question = lines[0].strip()
                answer = '\n'.join(lines[1:]).strip()
                
                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å
                kb_entry = {
                    "question": question,
                    "answer": answer,
                    "similarity_score": 0.0
                }
                
                self.knowledge_base.append(kb_entry)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.knowledge_base)} –∑–∞–ø–∏—Å–µ–π")
        return self.knowledge_base
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """–ü—Ä–æ—Å—Ç–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫"""
        
        query_lower = query.lower().strip()
        results = []
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ —Å–ª–æ–≤–∞–º
        for item in self.knowledge_base:
            score = 0.0
            question_lower = item['question'].lower().strip()
            
            # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞
            if question_lower == query_lower:
                score = 100.0
            elif question_lower in query_lower:
                score = 50.0
            elif query_lower in question_lower:
                score = 30.0
            
            # 2. –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            query_words = set(query_lower.split())
            question_words = set(question_lower.split())
            
            # –°–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ª–æ–≤
            word_overlap = len(query_words & question_words)
            if word_overlap > 0:
                score = max(score, word_overlap * 10.0)
            
            # 3. –ü–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º
            for word in query_words:
                if len(word) > 3:  # –¢–æ–ª—å–∫–æ –¥–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
                    for q_word in question_words:
                        if word in q_word or q_word in word:
                            score += 5.0
            
            # 4. –ü–æ–∏—Å–∫ –≤ –æ—Ç–≤–µ—Ç–µ
            answer_lower = item['answer'].lower()
            for word in query_words:
                if word in answer_lower:
                    score += 2.0
            
            if score > 0:
                item_copy = item.copy()
                item_copy['similarity_score'] = score
                results.append(item_copy)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        results.sort(key=lambda x: x['similarity_score'], reverse=True)
        return results[:top_k]
    
    def get_contextual_answer(self, query: str) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å"""
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø–∏—Å–∏
        results = self.search(query, top_k=3)
        
        if not results:
            return {
                "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.",
                "confidence": 0.0,
                "source": "fallback"
            }
        
        # –ë–µ—Ä–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        best_match = results[0]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = min(best_match["similarity_score"] / 100.0, 1.0)
        
        if confidence > 0.3:
            # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç
            return {
                "answer": best_match["answer"],
                "confidence": confidence,
                "source": "knowledge_base",
                "matched_question": best_match["question"]
            }
        else:
            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–∏–π –æ—Ç–≤–µ—Ç
            return {
                "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ?",
                "confidence": confidence,
                "source": "low_confidence",
                "suggestions": [r["question"] for r in results[:3]]
            }

def test_simple_search():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    simple_search = SimpleEffectiveSearch()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
    simple_search.load_knowledge_base()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–ü–æ—á–µ–º—É —Ç–∞–∫ –¥–æ—Ä–æ–≥–æ?",
        "–ö–∞–∫ –∑–∞–ø–ª–∞—Ç–∏—Ç—å –∑–∞ –ø–æ–µ–∑–¥–∫—É?",
        "–ú–æ–∂–Ω–æ –ª–∏ –∑–∞–∫–∞–∑–∞—Ç—å –∑–∞—Ä–∞–Ω–µ–µ?",
        "–ö–∞–∫ —Å—Ç–∞—Ç—å –≤–æ–¥–∏—Ç–µ–ª–µ–º?",
        "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è",
        "–ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –Ω–∞—Ü–µ–Ω–∫–∞?",
        "–ì–¥–µ –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É?",
        "–ö–∞–∫ –¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å—ã–ª–∫—É?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º—Ñ–æ—Ä—Ç?",
        "–ü–æ—á–µ–º—É —Å—á–∏—Ç–∞—é—Ç –≤—Ä–µ–º—è?"
    ]
    
    print("\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    
    for query in test_queries:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {query}")
        
        result = simple_search.get_contextual_answer(query)
        
        print(f"üìù –û—Ç–≤–µ—Ç: {result['answer'][:100]}...")
        print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2f}")
        print(f"üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫: {result['source']}")
        
        if 'matched_question' in result:
            print(f"üîó –°–æ–≤–ø–∞–≤—à–∏–π –≤–æ–ø—Ä–æ—Å: {result['matched_question']}")
        
        if 'suggestions' in result:
            print(f"üí° –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {result['suggestions']}")

if __name__ == "__main__":
    print("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ APARU...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º
    test_simple_search()
    
    print("\n‚úÖ –ü—Ä–æ—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –≥–æ—Ç–æ–≤–∞!")
    print("üéØ –¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç!")
