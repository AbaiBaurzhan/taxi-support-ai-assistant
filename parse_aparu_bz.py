#!/usr/bin/env python3
"""
üìä APARU BZ.txt Parser
–ü–∞—Ä—Å–∏—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏–∑ —Ñ–∞–π–ª–∞ BZ.txt –∏ —Å–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
"""

import json
import re
import logging
from typing import List, Dict, Any
from pathlib import Path

logger = logging.getLogger(__name__)

class APARUBZParser:
    def __init__(self):
        self.knowledge_base = []
        
    def parse_bz_file(self, file_path: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª BZ.txt –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã"""
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–ª–æ–∫–∏ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
            blocks = self._split_into_blocks(content)
            
            for i, block in enumerate(blocks):
                if block.strip():
                    qa_item = self._parse_qa_block(block, i)
                    if qa_item:
                        self.knowledge_base.append(qa_item)
            
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(self.knowledge_base)} –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤")
            return self.knowledge_base
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞: {e}")
            raise
    
    def _split_into_blocks(self, content: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–∞ –±–ª–æ–∫–∏ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "- question:" –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –±–ª–æ–∫–æ–≤
        pattern = r'- question:'
        blocks = re.split(pattern, content)
        
        # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –±–ª–æ–∫–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ "- question:"
        result = []
        for i, block in enumerate(blocks):
            if block.strip():
                if i > 0:  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –∫ –ø–µ—Ä–≤–æ–º—É –±–ª–æ–∫—É
                    block = "- question:" + block
                result.append(block)
        
        return result
    
    def _parse_qa_block(self, block: str, index: int) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
        try:
            lines = block.strip().split('\n')
            
            question = ""
            answer_lines = []
            in_answer = False
            
            for line in lines:
                line = line.strip()
                
                if line.startswith('- question:'):
                    question = line.replace('- question:', '').strip()
                    in_answer = True
                elif in_answer and line.startswith('answer:'):
                    answer_lines.append(line.replace('answer:', '').strip())
                elif in_answer and line and not line.startswith('-'):
                    answer_lines.append(line)
            
            if question and answer_lines:
                answer = ' '.join(answer_lines).strip()
                
                # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
                answer = re.sub(r'\s+', ' ', answer)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                keywords = self._extract_keywords(question + " " + answer)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                category = self._determine_category(question, answer)
                
                return {
                    'id': f"aparu_{index}",
                    'question': question,
                    'answer': answer,
                    'category': category,
                    'keywords': keywords,
                    'source': 'BZ.txt',
                    'original_text': block.strip()
                }
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–ª–æ–∫–∞: {e}")
            return None
    
    def _extract_keywords(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()
        
        # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words = text.split()
        
        # –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏ –∫–∞–∑–∞—Ö—Å–∫–æ–º
        stop_words = {
            '–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–æ—Ç', '–¥–æ', '–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É',
            '—ç—Ç–æ', '—Ç–æ', '—Ç–∞', '—Ç–µ', '–º–æ–π', '–º–æ—è', '–º–æ–µ', '–º–æ–∏', '–≤–∞—à', '–≤–∞—à–∞', '–≤–∞—à–µ', '–≤–∞—à–∏',
            '–Ω–∞—à', '–Ω–∞—à–∞', '–Ω–∞—à–µ', '–Ω–∞—à–∏', '–µ–≥–æ', '–µ—ë', '–∏—Ö', '–æ–Ω', '–æ–Ω–∞', '–æ–Ω–æ', '–æ–Ω–∏', '–º—ã', '–≤—ã',
            '–º–µ–Ω—è', '—Ç–µ–±—è', '–µ–≥–æ', '–µ—ë', '–Ω–∞—Å', '–≤–∞—Å', '–∏—Ö', '–º–Ω–µ', '—Ç–µ–±–µ', '–µ–º—É', '–µ–π', '–Ω–∞–º', '–≤–∞–º',
            '–∏–º', '–º–Ω–æ–π', '—Ç–æ–±–æ–π', '–∏–º', '–µ–π', '–Ω–∞–º–∏', '–≤–∞–º–∏', '–∏–º–∏', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ', '—Å–ø–∞—Å–∏–±–æ',
            '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', '–∏–∑–≤–∏–Ω–∏—Ç–µ', '—Å', '—É–≤–∞–∂–µ–Ω–∏–µ–º', '–∫–æ–º–∞–Ω–¥–∞', '–∞–ø–∞—Ä—É'
        }
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞
        keywords = []
        for word in words:
            if len(word) > 2 and word not in stop_words:
                keywords.append(word)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        unique_keywords = list(dict.fromkeys(keywords))[:15]
        
        return unique_keywords
    
    def _determine_category(self, question: str, answer: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"""
        text = (question + " " + answer).lower()
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ APARU
        categories = {
            'pricing': ['–Ω–∞—Ü–µ–Ω–∫–∞', '—Ç–∞—Ä–∏—Ñ', '–∫–æ–º—Ñ–æ—Ä—Ç', '—Ä–∞—Å—Ü–µ–Ω–∫–∞', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–º–æ—Ç–æ—á–∞—Å—ã', '—Ç–∞–∫—Å–æ–º–µ—Ç—Ä'],
            'booking': ['–∑–∞–∫–∞–∑', '–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π', '–¥–æ—Å—Ç–∞–≤–∫–∞', '—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å'],
            'driver': ['–≤–æ–¥–∏—Ç–µ–ª—å', '–ø—Ä–∏–Ω–∏–º–∞—Ç—å', '–∑–∞–∫–∞–∑—ã', '–±–∞–ª–∞–Ω—Å', '–ø–æ–ø–æ–ª–Ω–∏—Ç—å'],
            'technical': ['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '—Ä–∞–±–æ—Ç–∞–µ—Ç', '–æ–±–Ω–æ–≤–∏—Ç—å', 'gps', '–Ω–∞—Å—Ç—Ä–æ–π–∫–∞'],
            'general': ['—á—Ç–æ', '–∫–∞–∫', '–ø–æ—á–µ–º—É', '–≥–¥–µ', '–∫–æ–≥–¥–∞']
        }
        
        for category, keywords in categories.items():
            for keyword in keywords:
                if keyword in text:
                    return category
        
        return 'general'
    
    def save_to_json(self, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.knowledge_base, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_path}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            raise
    
    def save_to_csv(self, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –≤ CSV —Ñ–∞–π–ª"""
        try:
            import pandas as pd
            
            df = pd.DataFrame(self.knowledge_base)
            df.to_csv(output_path, index=False, encoding='utf-8')
            
            logger.info(f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_path}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV: {e}")
            raise
    
    def get_statistics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        if not self.knowledge_base:
            return {}
        
        categories = {}
        total_keywords = 0
        
        for item in self.knowledge_base:
            category = item['category']
            categories[category] = categories.get(category, 0) + 1
            total_keywords += len(item['keywords'])
        
        return {
            'total_questions': len(self.knowledge_base),
            'categories': categories,
            'avg_keywords_per_question': total_keywords / len(self.knowledge_base),
            'total_keywords': total_keywords,
            'source': 'BZ.txt'
        }
    
    def preview_data(self, limit: int = 5):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö"""
        print("üìä –ü—Ä–µ–≤—å—é –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π APARU:")
        print("=" * 60)
        
        for i, item in enumerate(self.knowledge_base[:limit]):
            print(f"\n{i+1}. ID: {item['id']}")
            print(f"   –í–æ–ø—Ä–æ—Å: {item['question']}")
            print(f"   –û—Ç–≤–µ—Ç: {item['answer'][:100]}...")
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {item['category']}")
            print(f"   –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(item['keywords'][:5])}")
            print("-" * 60)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logging.basicConfig(level=logging.INFO)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = APARUBZParser()
    
    # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª BZ.txt
    bz_file = "database_Aparu/BZ.txt"
    
    if not Path(bz_file).exists():
        print(f"‚ùå –§–∞–π–ª {bz_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    try:
        # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
        knowledge_base = parser.parse_bz_file(bz_file)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é
        parser.preview_data(5)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        parser.save_to_json("aparu_knowledge_base.json")
        parser.save_to_csv("aparu_knowledge_base.csv")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = parser.get_statistics()
        print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìÅ JSON: aparu_knowledge_base.json")
        print(f"üìÅ CSV: aparu_knowledge_base.csv")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()
