#!/usr/bin/env python3
"""
üìä –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π APARU
–ü–∞—Ä—Å–∏—Ç –ø–æ–ª–Ω—É—é –±–∞–∑—É BZ.txt —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
"""

import json
import logging
import re
from typing import Dict, List, Any, Tuple
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProfessionalBZParser:
    def __init__(self):
        self.parsed_data = []
        
    def parse_full_bz_file(self, file_path: str = "BZ.txt") -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª BZ.txt"""
        logger.info(f"üìö –ü–∞—Ä—Å–∏–º –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–ª–æ–∫–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É "- question_variations:" –∏–ª–∏ "- question:"
            blocks = re.split(r'\n(?=- question)', content)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π –±–ª–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ
            if blocks and not blocks[0].startswith('- question'):
                blocks[0] = '- question' + blocks[0]
            
            for block in blocks:
                if block.strip() and (block.strip().startswith('- question_variations:') or block.strip().startswith('- question:')):
                    parsed_item = self._parse_question_block(block.strip())
                    if parsed_item:
                        self.parsed_data.append(parsed_item)
            
            logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(self.parsed_data)} –∑–∞–ø–∏—Å–µ–π")
            return self.parsed_data
            
        except FileNotFoundError:
            logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []
    
    def _parse_question_block(self, block: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ —Å –≤–æ–ø—Ä–æ—Å–æ–º"""
        lines = block.split('\n')
        
        main_question = None
        question_variations = []
        keywords = []
        answer = ""
        
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('- question_variations:'):
                current_section = 'variations'
                continue
            elif line.startswith('- question:'):
                current_section = 'main_question'
                main_question = line.replace('- question:', '').strip()
                continue
            elif line.startswith('keywords:'):
                current_section = 'keywords'
                keywords_text = line.replace('keywords:', '').strip()
                if keywords_text.startswith('[') and keywords_text.endswith(']'):
                    keywords_text = keywords_text[1:-1]
                    keywords = [kw.strip() for kw in keywords_text.split(',')]
                continue
            elif line.startswith('answer:'):
                current_section = 'answer'
                answer = line.replace('answer:', '').strip()
                continue
            elif line and current_section == 'variations':
                question_variations.append(line)
            elif line and current_section == 'answer':
                answer += " " + line
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∏–∑ –≤–∞—Ä–∏–∞—Ü–∏–π
        if not main_question and question_variations:
            main_question = question_variations[0]
        
        if main_question and answer:
            return {
                'question': main_question,
                'answer': answer.strip(),
                'variations': question_variations,
                'keywords': keywords,
                'category': self._categorize_question(main_question),
                'confidence': self._calculate_confidence(main_question, answer, keywords),
                'source': 'BZ.txt',
                'id': len(self.parsed_data) + 1
            }
        
        return None
    
    def _categorize_question(self, question: str) -> str:
        """–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['–Ω–∞—Ü–µ–Ω–∫–∞', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ä–∞—Å—Ü–µ–Ω–∫–∞', '–¥–æ—Ä–æ–≥–æ', '–¥–µ—à–µ–≤–æ', '—Ç–∞—Ä–∏—Ñ']):
            return 'pricing'
        elif any(word in question_lower for word in ['–∑–∞–∫–∞–∑', '–ø–æ–µ–∑–¥–∫–∞', '—Ç–∞–∫—Å–∏', '–≤—ã–∑–æ–≤', '–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π', '–æ—Ç–º–µ–Ω–∏—Ç—å']):
            return 'booking'
        elif any(word in question_lower for word in ['–±–∞–ª–∞–Ω—Å', '–ø–æ–ø–æ–ª–Ω–∏—Ç—å', '–æ–ø–ª–∞—Ç–∞', '–ø–ª–∞—Ç–µ–∂', '–∫–∞—Ä—Ç–∞', 'qiwi', 'kaspi']):
            return 'payment'
        elif any(word in question_lower for word in ['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '—Ç–∞–∫—Å–æ–º–µ—Ç—Ä', '–º–æ—Ç–æ—á–∞—Å—ã', 'gps', '–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç', '–æ–±–Ω–æ–≤–∏—Ç—å']):
            return 'technical'
        elif any(word in question_lower for word in ['–¥–æ—Å—Ç–∞–≤–∫–∞', '–∫—É—Ä—å–µ—Ä', '–ø–æ—Å—ã–ª–∫–∞', '–æ—Ç–ø—Ä–∞–≤–∏—Ç—å']):
            return 'delivery'
        elif any(word in question_lower for word in ['–≤–æ–¥–∏—Ç–µ–ª—å', '–∫–æ–Ω—Ç–∞–∫—Ç—ã', '—Å–≤—è–∑—å', '–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–∞–∫–∞–∑—ã', '—Ä–∞–±–æ—Ç–∞—Ç—å']):
            return 'driver'
        elif any(word in question_lower for word in ['–æ—Ç–º–µ–Ω–∏—Ç—å', '–æ—Ç–º–µ–Ω–∞', '–æ—Ç–∫–∞–∑', '–ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å']):
            return 'cancellation'
        elif any(word in question_lower for word in ['–∂–∞–ª–æ–±–∞', '–ø—Ä–æ–±–ª–µ–º–∞', '–Ω–µ–¥–æ–≤–æ–ª–µ–Ω', '–ø–ª–æ—Ö–æ']):
            return 'complaint'
        else:
            return 'general'
    
    def _calculate_confidence(self, question: str, answer: str, keywords: List[str]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"""
        confidence = 0.7  # –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
        if '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ' in answer.lower():
            confidence += 0.1
        if '–∫–æ–º–∞–Ω–¥–∞ –∞–ø–∞—Ä—É' in answer.lower():
            confidence += 0.1
        if len(answer) > 100:
            confidence += 0.05
        if len(answer) > 200:
            confidence += 0.05
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–π –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if len(keywords) > 5:
            confidence += 0.05
        
        return min(confidence, 1.0)
    
    def save_professional_knowledge_base(self, output_path: str = "professional_aparu_knowledge.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –±–∞–∑—É: {output_path}")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.parsed_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –±–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {len(self.parsed_data)} –∑–∞–ø–∏—Å–µ–π")
        return output_path

if __name__ == "__main__":
    parser = ProfessionalBZParser()
    
    # –ü–∞—Ä—Å–∏–º –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª
    parsed_data = parser.parse_full_bz_file("BZ.txt")
    
    if parsed_data:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –±–∞–∑—É
        json_path = parser.save_professional_knowledge_base()
        
        print(f"üéØ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìÅ JSON: {json_path}")
        print(f"üìä –ó–∞–ø–∏—Å–µ–π: {len(parsed_data)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        categories = {}
        total_variations = 0
        total_keywords = 0
        
        for item in parsed_data:
            cat = item.get('category', 'general')
            categories[cat] = categories.get(cat, 0) + 1
            total_variations += len(item.get('variations', []))
            total_keywords += len(item.get('keywords', []))
        
        print(f"\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for cat, count in categories.items():
            print(f"   {cat}: {count} –∑–∞–ø–∏—Å–µ–π")
        
        print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í–∞—Ä–∏–∞—Ü–∏–π –≤–æ–ø—Ä–æ—Å–æ–≤: {total_variations}")
        print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {total_keywords}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤–∞—Ä–∏–∞—Ü–∏–π –Ω–∞ –∑–∞–ø–∏—Å—å: {total_variations / len(parsed_data):.1f}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–∞ –∑–∞–ø–∏—Å—å: {total_keywords / len(parsed_data):.1f}")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞!")
