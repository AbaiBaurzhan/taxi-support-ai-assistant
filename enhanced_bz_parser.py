#!/usr/bin/env python3
"""
üìä –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π APARU
–ü–∞—Ä—Å–∏—Ç –Ω–æ–≤—É—é –±–∞–∑—É BZ.txt —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
"""

import json
import logging
import re
from typing import Dict, List, Any
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedBZParser:
    def __init__(self):
        self.parsed_data = []
        
    def parse_bz_file(self, file_path: str = "BZ.txt") -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª BZ.txt —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏ –≤–æ–ø—Ä–æ—Å–æ–≤"""
        logger.info(f"üìö –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–ª–æ–∫–∏ –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é
            blocks = content.split('\n\t\n')
            
            # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥
            if len(blocks) == 1:
                # –ò—â–µ–º –±–ª–æ–∫–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É "- question"
                blocks = re.split(r'\n(?=- question)', content)
                if len(blocks) > 1:
                    blocks[0] = blocks[0].replace('- question', '- question')  # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–π –±–ª–æ–∫
            
            for block in blocks:
                if block.strip():
                    parsed_item = self._parse_block(block.strip())
                    if parsed_item:
                        self.parsed_data.append(parsed_item)
            
            logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(self.parsed_data)} –∑–∞–ø–∏—Å–µ–π")
            return self.parsed_data
            
        except FileNotFoundError:
            logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []
    
    def _parse_block(self, block: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω –±–ª–æ–∫ –¥–∞–Ω–Ω—ã—Ö"""
        lines = block.split('\n')
        
        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –≤–æ–ø—Ä–æ—Å
        main_question = None
        question_variations = []
        keywords = []
        answer = ""
        
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('- question_variations:'):
                current_section = 'variations'
                continue
            elif line.startswith('- question:'):
                current_section = 'main_question'
                main_question = line.replace('- question:', '').strip()
                continue
            elif line.startswith('keywords:'):
                current_section = 'keywords'
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏
                keywords_text = line.replace('keywords:', '').strip()
                if keywords_text.startswith('[') and keywords_text.endswith(']'):
                    keywords_text = keywords_text[1:-1]  # –£–±–∏—Ä–∞–µ–º —Å–∫–æ–±–∫–∏
                    keywords = [kw.strip() for kw in keywords_text.split(',')]
                continue
            elif line.startswith('answer:'):
                current_section = 'answer'
                answer = line.replace('answer:', '').strip()
                continue
            elif line and current_section == 'variations':
                question_variations.append(line)
            elif line and current_section == 'answer':
                answer += " " + line
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∏–∑ –≤–∞—Ä–∏–∞—Ü–∏–π
        if not main_question and question_variations:
            main_question = question_variations[0]
        
        if main_question and answer:
            return {
                'question': main_question,
                'answer': answer.strip(),
                'variations': question_variations,
                'keywords': keywords,
                'category': self._categorize_question(main_question),
                'confidence': self._calculate_confidence(main_question, answer, keywords),
                'source': 'BZ.txt'
            }
        
        return None
    
    def _categorize_question(self, question: str) -> str:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['–Ω–∞—Ü–µ–Ω–∫–∞', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ä–∞—Å—Ü–µ–Ω–∫–∞', '–¥–æ—Ä–æ–≥–æ', '–¥–µ—à–µ–≤–æ']):
            return 'pricing'
        elif any(word in question_lower for word in ['–∑–∞–∫–∞–∑', '–ø–æ–µ–∑–¥–∫–∞', '—Ç–∞–∫—Å–∏', '–≤—ã–∑–æ–≤', '–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π']):
            return 'booking'
        elif any(word in question_lower for word in ['–±–∞–ª–∞–Ω—Å', '–ø–æ–ø–æ–ª–Ω–∏—Ç—å', '–æ–ø–ª–∞—Ç–∞', '–ø–ª–∞—Ç–µ–∂', '–∫–∞—Ä—Ç–∞']):
            return 'payment'
        elif any(word in question_lower for word in ['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '—Ç–∞–∫—Å–æ–º–µ—Ç—Ä', '–º–æ—Ç–æ—á–∞—Å—ã', 'gps', '–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç']):
            return 'technical'
        elif any(word in question_lower for word in ['–¥–æ—Å—Ç–∞–≤–∫–∞', '–∫—É—Ä—å–µ—Ä', '–ø–æ—Å—ã–ª–∫–∞']):
            return 'delivery'
        elif any(word in question_lower for word in ['–≤–æ–¥–∏—Ç–µ–ª—å', '–∫–æ–Ω—Ç–∞–∫—Ç—ã', '—Å–≤—è–∑—å', '–ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–∞–∫–∞–∑—ã']):
            return 'driver'
        elif any(word in question_lower for word in ['–æ—Ç–º–µ–Ω–∏—Ç—å', '–æ—Ç–º–µ–Ω–∞', '–æ—Ç–∫–∞–∑']):
            return 'cancellation'
        elif any(word in question_lower for word in ['–∂–∞–ª–æ–±–∞', '–ø—Ä–æ–±–ª–µ–º–∞', '–Ω–µ–¥–æ–≤–æ–ª–µ–Ω']):
            return 'complaint'
        else:
            return 'general'
    
    def _calculate_confidence(self, question: str, answer: str, keywords: List[str]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        confidence = 0.5  # –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
        if '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ' in answer.lower():
            confidence += 0.1
        if '–∫–æ–º–∞–Ω–¥–∞ –∞–ø–∞—Ä—É' in answer.lower():
            confidence += 0.1
        if len(answer) > 100:
            confidence += 0.1
        if len(answer) > 200:
            confidence += 0.1
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–π
        if len(keywords) > 5:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def save_to_json(self, output_path: str = "enhanced_aparu_knowledge_base.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ JSON"""
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON: {output_path}")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.parsed_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(self.parsed_data)} –∑–∞–ø–∏—Å–µ–π")
        return output_path
    
    def create_search_index(self, output_path: str = "enhanced_search_index.pkl"):
        """–°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        import pickle
        
        logger.info(f"üîç –°–æ–∑–¥–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å: {output_path}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        keyword_index = {}
        question_index = {}
        
        for i, item in enumerate(self.parsed_data):
            # –ò–Ω–¥–µ–∫—Å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            for keyword in item.get('keywords', []):
                if keyword not in keyword_index:
                    keyword_index[keyword] = []
                keyword_index[keyword].append(i)
            
            # –ò–Ω–¥–µ–∫—Å –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º
            question_index[item['question'].lower()] = i
            
            # –ò–Ω–¥–µ–∫—Å –ø–æ –≤–∞—Ä–∏–∞—Ü–∏—è–º
            for variation in item.get('variations', []):
                question_index[variation.lower()] = i
        
        index_data = {
            'keyword_index': keyword_index,
            'question_index': question_index,
            'data': self.parsed_data
        }
        
        with open(output_path, 'wb') as f:
            pickle.dump(index_data, f)
        
        logger.info(f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω: {len(keyword_index)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, {len(question_index)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        return output_path

if __name__ == "__main__":
    parser = EnhancedBZParser()
    
    # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª
    parsed_data = parser.parse_bz_file("BZ.txt")
    
    if parsed_data:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        json_path = parser.save_to_json()
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        index_path = parser.create_search_index()
        
        print(f"üéØ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìÅ JSON: {json_path}")
        print(f"üîç –ò–Ω–¥–µ–∫—Å: {index_path}")
        print(f"üìä –ó–∞–ø–∏—Å–µ–π: {len(parsed_data)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        categories = {}
        for item in parsed_data:
            cat = item.get('category', 'general')
            categories[cat] = categories.get(cat, 0) + 1
        
        print(f"\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for cat, count in categories.items():
            print(f"   {cat}: {count} –∑–∞–ø–∏—Å–µ–π")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞!")
