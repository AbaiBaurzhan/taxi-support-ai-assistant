#!/usr/bin/env python3
"""
üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ü–û–ò–°–ö–û–í–ê–Ø LLM –°–ò–°–¢–ï–ú–ê APARU AI
–ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
"""

import json
import logging
import requests
from typing import Dict, Any, List, Optional
from datetime import datetime
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OptimizedSearchLLMClient:
    def __init__(self):
        self.ollama_url = os.environ.get("OLLAMA_URL", "http://localhost:11434")
        self.model_name = "aparu-senior-ai"
        self.ollama_available = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.knowledge_base = self._load_knowledge_base()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
        self._check_ollama_model()
    
    def _load_knowledge_base(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤"""
        try:
            with open("senior_ai_knowledge_base.json", "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: senior_ai_knowledge_base.json")
                return data
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
            return []
    
    def _check_ollama_model(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –∏ –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                if any(m["name"].startswith(self.model_name) for m in models):
                    self.ollama_available = True
                    logger.info(f"‚úÖ Ollama –∏ –º–æ–¥–µ–ª—å '{self.model_name}' –¥–æ—Å—Ç—É–ø–Ω—ã")
                else:
                    logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ Ollama")
            else:
                logger.warning(f"‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {e}")
    
    def find_best_answer(self, question: str) -> Dict[str, Any]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        start_time = datetime.now()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –ø–æ–∏—Å–∫–∞, –∞ –Ω–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        if self.ollama_available:
            try:
                logger.info("üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞...")
                result = self._llm_search_answer(question)
                if result:
                    processing_time = (datetime.now() - start_time).total_seconds()
                    logger.info(f"‚úÖ LLM –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {processing_time:.2f}—Å")
                    return result
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –ø–æ–∏—Å–∫–∞: {e}")
        
        # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –ø–æ–∏—Å–∫—É
        logger.info("üîÑ Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –ø–æ–∏—Å–∫—É...")
        return self._simple_search(question)
    
    def _llm_search_answer(self, question: str) -> Dict[str, Any]:
        """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        try:
            # –ö–û–†–û–¢–ö–ò–ô –ü–†–û–ú–ü–¢ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            search_prompt = f"""–ù–∞–π–¥–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å: "{question}"

–ë–∞–∑–∞ FAQ:
1. –ù–∞—Ü–µ–Ω–∫–∞ - –¥–æ–ø–ª–∞—Ç–∞ –∑–∞ —Å–ø—Ä–æ—Å
2. –î–æ—Å—Ç–∞–≤–∫–∞ - –∫—É—Ä—å–µ—Ä—Å–∫–∏–µ —É—Å–ª—É–≥–∏  
3. –ë–∞–ª–∞–Ω—Å - –ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—á–µ—Ç–∞
4. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
5. –¢–∞—Ä–∏—Ñ—ã - –≤–∏–¥—ã –ø–æ–µ–∑–¥–æ–∫

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä–æ–º (1-5):"""

            payload = {
                "model": self.model_name,
                "prompt": search_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.01,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
                    "num_predict": 3,      # –¢–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä
                    "num_ctx": 256,        # –ö–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    "repeat_penalty": 1.0,
                    "top_k": 1,            # –¢–æ–ª—å–∫–æ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
                    "top_p": 0.1,          # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                    "stop": ["\n", ".", "!", "?", "–û—Ç–≤–µ—Ç:", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è:"]  # –†–∞–Ω–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
                }
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=8  # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–∞–π–º–∞—É—Ç
            )
            
            if response.status_code == 200:
                data = response.json()
                answer = data.get('response', '').strip()
                
                # –ü–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_num = self._parse_category_number(answer)
                if category_num:
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
                    if 1 <= category_num <= len(self.knowledge_base):
                        kb_item = self.knowledge_base[category_num - 1]
                        return {
                            "answer": kb_item.get("answer", "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"),
                            "category": kb_item.get("question", f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {category_num}"),
                            "confidence": 0.95,
                            "source": "optimized_llm_search"
                        }
                
                logger.warning(f"‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {answer}")
                return None
            
            logger.warning(f"‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {response.status_code}")
            return None
            
        except requests.exceptions.Timeout:
            logger.error(f"‚ùå LLM –ø–æ–∏—Å–∫ —Ç–∞–π–º–∞—É—Ç (>8—Å)")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –ø–æ–∏—Å–∫–∞: {e}")
            return None
    
    def _parse_category_number(self, answer: str) -> Optional[int]:
        """–ü–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        try:
            # –ò—â–µ–º —á–∏—Å–ª–æ –≤ –æ—Ç–≤–µ—Ç–µ
            import re
            numbers = re.findall(r'\d+', answer)
            if numbers:
                num = int(numbers[0])
                if 1 <= num <= len(self.knowledge_base):
                    return num
            return None
        except:
            return None
    
    def _simple_search(self, question: str) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback)"""
        question_lower = question.lower()
        
        # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for item in self.knowledge_base:
            keywords = item.get("keywords", [])
            variations = item.get("variations", [])
            answer = item.get("answer", "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            question_text = item.get("question", "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            for keyword in keywords:
                if keyword.lower() in question_lower:
                    return {
                        "answer": answer,
                        "category": question_text,
                        "confidence": 0.8,
                        "source": "simple_search"
                    }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏
            for variation in variations:
                if variation.lower() in question_lower:
                    return {
                        "answer": answer,
                        "category": question_text,
                        "confidence": 0.8,
                        "source": "simple_search"
                    }
        
        # Fallback
        return {
            "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏.",
            "category": "unknown",
            "confidence": 0.0,
            "source": "fallback"
        }

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    client = OptimizedSearchLLMClient()
    
    test_questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∞?",
        "–ö–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É?",
        "–ö–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç–∞?"
    ]
    
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ô –ü–û–ò–°–ö–û–í–û–ô LLM –°–ò–°–¢–ï–ú–´:")
    print("=" * 60)
    
    for question in test_questions:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        result = client.find_best_answer(question)
        print(f"‚úÖ –û—Ç–≤–µ—Ç: {result['answer'][:100]}...")
        print(f"üìä –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result['category']}")
        print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']}")
        print(f"üîß –ò—Å—Ç–æ—á–Ω–∏–∫: {result['source']}")
        print("-" * 40)
