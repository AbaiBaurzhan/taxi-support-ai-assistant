#!/usr/bin/env python3
"""
üîç –ü–û–ò–°–ö–û–í–ê–Ø LLM –°–ò–°–¢–ï–ú–ê APARU AI
LLM —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ - –Ω–∞—Ö–æ–¥–∏—Ç –≥–æ—Ç–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ –±–∞–∑—ã
"""

import json
import logging
import requests
from typing import Dict, Any, List, Optional
from datetime import datetime
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SearchBasedLLMClient:
    def __init__(self):
        self.ollama_url = os.environ.get("OLLAMA_URL", "http://localhost:11434")
        self.model_name = "aparu-senior-ai"
        self.ollama_available = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.knowledge_base = self._load_knowledge_base()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
        self._check_ollama_model()
    
    def _load_knowledge_base(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            knowledge_files = [
                "senior_ai_knowledge_base.json",
                "enhanced_aparu_knowledge_base.json", 
                "aparu_knowledge_base.json",
                "kb.json"
            ]
            
            for file_path in knowledge_files:
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: {file_path}")
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        if isinstance(data, list):
                            return data
                        # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
                        elif isinstance(data, dict):
                            return list(data.values())
                        else:
                            logger.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {type(data)}")
                            continue
                            
                except FileNotFoundError:
                    continue
            
            # Fallback - –ø—Ä–æ—Å—Ç–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return [
                {
                    "id": 1,
                    "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∞?",
                    "answer": "–ù–∞—Ü–µ–Ω–∫–∞ - —ç—Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–ª–∞—Ç–∞ –∑–∞ –ø–æ–≤—ã—à–µ–Ω–Ω—ã–π —Å–ø—Ä–æ—Å. –û–Ω–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏–≤–ª–µ—á—å –±–æ–ª—å—à–µ –≤–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è.",
                    "variations": ["–Ω–∞—Ü–µ–Ω–∫–∞", "–¥–æ—Ä–æ–≥–æ", "–ø–æ–¥–æ—Ä–æ–∂–∞–Ω–∏–µ", "–ø–æ–≤—ã—à–µ–Ω–∏–µ", "–¥–æ–ø–ª–∞—Ç–∞"],
                    "keywords": ["–Ω–∞—Ü–µ–Ω–∫–∞", "–¥–æ—Ä–æ–≥–æ", "–ø–æ–¥–æ—Ä–æ–∂–∞–Ω–∏–µ", "–ø–æ–≤—ã—à–µ–Ω–∏–µ", "–¥–æ–ø–ª–∞—Ç–∞"]
                },
                {
                    "id": 2,
                    "question": "–ö–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É?",
                    "answer": "–î–ª—è –∑–∞–∫–∞–∑–∞ –¥–æ—Å—Ç–∞–≤–∫–∏: –æ—Ç–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Üí –≤—ã–±–µ—Ä–∏—Ç–µ '–î–æ—Å—Ç–∞–≤–∫–∞' ‚Üí —É–∫–∞–∂–∏—Ç–µ –∞–¥—Ä–µ—Å–∞ ‚Üí –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –∑–∞–∫–∞–∑.",
                    "variations": ["–¥–æ—Å—Ç–∞–≤–∫–∞", "–∫—É—Ä—å–µ—Ä", "–ø–æ—Å—ã–ª–∫–∞", "–æ—Ç–ø—Ä–∞–≤–∏—Ç—å", "–∑–∞–∫–∞–∑–∞—Ç—å"],
                    "keywords": ["–¥–æ—Å—Ç–∞–≤–∫–∞", "–∫—É—Ä—å–µ—Ä", "–ø–æ—Å—ã–ª–∫–∞", "–æ—Ç–ø—Ä–∞–≤–∏—Ç—å", "–∑–∞–∫–∞–∑–∞—Ç—å"]
                },
                {
                    "id": 3,
                    "question": "–ö–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å?",
                    "answer": "–î–ª—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞: –æ—Ç–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Üí '–ü—Ä–æ—Ñ–∏–ª—å' ‚Üí '–ü–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å' ‚Üí –≤—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã.",
                    "variations": ["–±–∞–ª–∞–Ω—Å", "—Å—á–µ—Ç", "–∫–æ—à–µ–ª–µ–∫", "–ø–æ–ø–æ–ª–Ω–∏—Ç—å", "–ø–ª–∞—Ç–µ–∂"],
                    "keywords": ["–±–∞–ª–∞–Ω—Å", "—Å—á–µ—Ç", "–∫–æ—à–µ–ª–µ–∫", "–ø–æ–ø–æ–ª–Ω–∏—Ç—å", "–ø–ª–∞—Ç–µ–∂"]
                }
            ]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
            return []
    
    def _check_ollama_model(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –∏ –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                if any(m["name"].startswith(self.model_name) for m in models):
                    self.ollama_available = True
                    logger.info(f"‚úÖ Ollama –∏ –º–æ–¥–µ–ª—å '{self.model_name}' –¥–æ—Å—Ç—É–ø–Ω—ã")
                else:
                    logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ Ollama")
            else:
                logger.warning(f"‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {e}")
    
    def find_best_answer(self, question: str) -> Dict[str, Any]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        start_time = datetime.now()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –ø–æ–∏—Å–∫–∞, –∞ –Ω–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        if self.ollama_available:
            try:
                logger.info("üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞...")
                result = self._llm_search_answer(question)
                if result:
                    processing_time = (datetime.now() - start_time).total_seconds()
                    logger.info(f"‚úÖ LLM –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {processing_time:.2f}—Å")
                    return result
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –ø–æ–∏—Å–∫–∞: {e}")
        
        # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –ø–æ–∏—Å–∫—É
        logger.info("üîÑ Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –ø–æ–∏—Å–∫—É...")
        return self._simple_search(question)
    
    def _llm_search_answer(self, question: str) -> Dict[str, Any]:
        """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞, –∞ –Ω–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            search_prompt = f"""–¢—ã ‚Äî –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è FAQ APARU. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {question}

–ë–ê–ó–ê –ó–ù–ê–ù–ò–ô:
{self._format_knowledge_base()}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –ù–∞–π–¥–∏ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
3. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "1", "2", "3")
4. –ù–ï –≥–µ–Ω–µ—Ä–∏—Ä—É–π –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç
5. –ù–ï –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–π –≤—ã–±–æ—Ä

–û–¢–í–ï–¢ (—Ç–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏):"""

            payload = {
                "model": self.model_name,
                "prompt": search_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.01,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                    "num_predict": 5,     # –¢–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    "num_ctx": 512,       # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
                    "repeat_penalty": 1.0,
                    "top_k": 1,           # –¢–æ–ª—å–∫–æ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
                    "top_p": 0.1,         # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                    "stop": ["\n", ".", "!", "?", "–û—Ç–≤–µ—Ç:", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è:"]  # –†–∞–Ω–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
                }
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=10  # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
            )
            
            if response.status_code == 200:
                data = response.json()
                answer = data.get('response', '').strip()
                
                # –ü–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_num = self._parse_category_number(answer)
                if category_num:
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
                    if 1 <= category_num <= len(self.knowledge_base):
                        kb_item = self.knowledge_base[category_num - 1]
                        return {
                            "answer": kb_item.get("answer", "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"),
                            "category": kb_item.get("question", f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {category_num}"),
                            "confidence": 0.95,
                            "source": "llm_search"
                        }
                
                logger.warning(f"‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {answer}")
                return None
            
            logger.warning(f"‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {response.status_code}")
            return None
            
        except requests.exceptions.Timeout:
            logger.error(f"‚ùå LLM –ø–æ–∏—Å–∫ —Ç–∞–π–º–∞—É—Ç (>10—Å)")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –ø–æ–∏—Å–∫–∞: {e}")
            return None
    
    def _format_knowledge_base(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è LLM"""
        formatted = ""
        for i, item in enumerate(self.knowledge_base, 1):
            question = item.get("question", f"–í–æ–ø—Ä–æ—Å {i}")
            answer = item.get("answer", "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            keywords = item.get("keywords", [])
            variations = item.get("variations", [])
            
            formatted += f"{i}. –í–û–ü–†–û–°: {question}\n"
            formatted += f"   –û–¢–í–ï–¢: {answer}\n"
            formatted += f"   –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê: {', '.join(keywords)}\n"
            formatted += f"   –í–ê–†–ò–ê–¶–ò–ò: {', '.join(variations[:5])}\n\n"
        
        return formatted
    
    def _parse_category_number(self, answer: str) -> Optional[int]:
        """–ü–∞—Ä—Å–∏—Ç –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        try:
            # –ò—â–µ–º —á–∏—Å–ª–æ –≤ –æ—Ç–≤–µ—Ç–µ
            import re
            numbers = re.findall(r'\d+', answer)
            if numbers:
                num = int(numbers[0])
                if 1 <= num <= len(self.knowledge_base):
                    return num
            return None
        except:
            return None
    
    def _simple_search(self, question: str) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback)"""
        question_lower = question.lower()
        
        # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for item in self.knowledge_base:
            keywords = item.get("keywords", [])
            variations = item.get("variations", [])
            answer = item.get("answer", "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            question_text = item.get("question", "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            for keyword in keywords:
                if keyword.lower() in question_lower:
                    return {
                        "answer": answer,
                        "category": question_text,
                        "confidence": 0.8,
                        "source": "simple_search"
                    }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏
            for variation in variations:
                if variation.lower() in question_lower:
                    return {
                        "answer": answer,
                        "category": question_text,
                        "confidence": 0.8,
                        "source": "simple_search"
                    }
        
        # Fallback
        return {
            "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏.",
            "category": "unknown",
            "confidence": 0.0,
            "source": "fallback"
        }

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    client = SearchBasedLLMClient()
    
    test_questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∞?",
        "–ö–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É?",
        "–ö–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç–∞?"
    ]
    
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–û–í–û–ô LLM –°–ò–°–¢–ï–ú–´:")
    print("=" * 50)
    
    for question in test_questions:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        result = client.find_best_answer(question)
        print(f"‚úÖ –û—Ç–≤–µ—Ç: {result['answer']}")
        print(f"üìä –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result['category']}")
        print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']}")
        print(f"üîß –ò—Å—Ç–æ—á–Ω–∏–∫: {result['source']}")
        print("-" * 30)
