"""
Ð¢ÐµÑÑ‚ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð´Ð»Ñ BZ.txt
"""

import sys
import os
sys.path.append('backend')

from enhanced_morphological_analyzer import enhance_classification_with_morphology, enhanced_analyzer
import json

def load_kb_data():
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹"""
    try:
        with open('backend/kb.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ kb.json: {e}")
        return None

def test_morphological_analysis():
    """Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
    print("ðŸ§ª Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹")
    print("=" * 60)
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹
    kb_data = load_kb_data()
    if not kb_data:
        return
    
    print(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(kb_data.get('faq', []))} FAQ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²")
    print()
    
    # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°Ð¼Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²
    test_queries = [
        # ÐÐ°Ñ†ÐµÐ½ÐºÐ°
        "Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ð½Ð°Ñ†ÐµÐ½ÐºÐ°?",
        "Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ñƒ Ð¼ÐµÐ½Ñ Ð¿Ð¾ÑÐ²Ð¸Ð»Ð°ÑÑŒ Ð´Ð¾Ð¿Ð»Ð°Ñ‚Ð°?",
        "Ñ‡Ñ‚Ð¾ Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ Ð¿Ð¾Ð²Ñ‹ÑˆÐ°ÑŽÑ‰Ð¸Ð¹ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚?",
        "Ð¾Ñ‚ÐºÑƒÐ´Ð° Ð±ÐµÑ€ÐµÑ‚ÑÑ Ð½Ð°Ð´Ð±Ð°Ð²ÐºÐ° Ðº Ñ†ÐµÐ½Ðµ?",
        "Ð·Ð°Ñ‡ÐµÐ¼ Ð´ÐµÐ»Ð°ÑŽÑ‚ Ð½Ð°Ñ†ÐµÐ½ÐºÑƒ?",
        "Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ ÑÑ‚Ð°Ð»Ð° Ð²Ñ‹ÑˆÐµ?",
        "Ð¸Ð·-Ð·Ð° Ñ‡ÐµÐ³Ð¾ Ñ†ÐµÐ½Ð° Ð²Ñ‹Ñ€Ð¾ÑÐ»Ð°?",
        
        # Ð¢Ð°Ñ€Ð¸Ñ„ ÐšÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚
        "Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ñ‚Ð°Ñ€Ð¸Ñ„ ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚?",
        "Ñ‡ÐµÐ¼ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð°ÐµÑ‚ÑÑ ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚ Ð¾Ñ‚ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð³Ð¾?",
        "Ñ‡Ñ‚Ð¾ Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð² Ñ‚Ð°Ñ€Ð¸Ñ„ ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚?",
        "ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚ ÑÑ‚Ð¾ ÐºÐ°ÐºÐ¸Ðµ Ð¼Ð°ÑˆÐ¸Ð½Ñ‹?",
        "Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð´Ð¾Ñ€Ð¾Ð¶Ðµ Ð¿Ð¾ÐµÐ·Ð´ÐºÐ° Ð² ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚Ðµ?",
        "ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚ ÑÑ‚Ð¾ ÐºÐ°Ð¼Ñ€Ð¸?",
        
        # Ð Ð°ÑÑ†ÐµÐ½ÐºÐ¸
        "ÐºÐ°Ðº ÑƒÐ·Ð½Ð°Ñ‚ÑŒ Ñ€Ð°ÑÑ†ÐµÐ½ÐºÑƒ?",
        "ÐºÐ°Ðº Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½ÑƒÑŽ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ?",
        "Ð³Ð´Ðµ Ð¼Ð¾Ð¶Ð½Ð¾ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ Ñ€Ð°ÑÑ†ÐµÐ½ÐºÐ¸ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ?",
        "Ð¼Ð¾Ð¶Ð½Ð¾ Ð»Ð¸ ÑƒÐ·Ð½Ð°Ñ‚ÑŒ Ñ†ÐµÐ½Ñƒ Ð´Ð¾ Ð·Ð°ÐºÐ°Ð·Ð°?",
        "ÐºÐ°Ðº Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ñ†ÐµÐ½Ñƒ Ð¿Ð¾ Ñ‚Ð°ÐºÑÐ¾Ð¼ÐµÑ‚Ñ€Ñƒ?",
        
        # ÐŸÑ€ÐµÐ´Ð·Ð°ÐºÐ°Ð·
        "ÐºÐ°Ðº ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°ÐºÐ°Ð·?",
        "Ð¼Ð¾Ð¶Ð½Ð¾ Ð»Ð¸ Ð²Ñ‹Ð·Ð²Ð°Ñ‚ÑŒ Ñ‚Ð°ÐºÑÐ¸ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ?",
        "ÐºÐ°Ðº Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒ Ð¿Ñ€ÐµÐ´Ð·Ð°ÐºÐ°Ð· Ð½Ð° Ð²Ñ€ÐµÐ¼Ñ?",
        "Ð¼Ð¾Ð¶Ð½Ð¾ Ð»Ð¸ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ð·Ð°ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¼Ð°ÑˆÐ¸Ð½Ñƒ?",
        
        # Ð”Ð¾ÑÑ‚Ð°Ð²ÐºÐ°
        "ÐºÐ°Ðº Ð·Ð°Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð·Ð°ÐºÐ°Ð· Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸?",
        "ÐºÐ°Ðº Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒ Ð·Ð°ÐºÐ°Ð· Ð½Ð° Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÑƒ?",
        "Ð³Ð´Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ñ‚Ð¸Ð¿ Ð·Ð°ÐºÐ°Ð·Ð° Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ°?",
        "ÐºÐ°Ðº Ð²Ñ‹Ð·Ð²Ð°Ñ‚ÑŒ ÐºÑƒÑ€ÑŒÐµÑ€Ð°?",
        
        # Ð’Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ
        "ÐºÐ°Ðº Ð¼Ð½Ðµ Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ Ð·Ð°ÐºÐ°Ð·Ñ‹?",
        "Ñ‡Ñ‚Ð¾ Ð½ÑƒÐ¶Ð½Ð¾ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÐµÐ¼?",
        "ÐºÐ°Ðº Ð·Ð°Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒÑÑ ÐºÐ°Ðº Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ?",
        "Ð³Ð´Ðµ Ð½Ð°Ð¹Ñ‚Ð¸ Ð»ÐµÐ½Ñ‚Ñƒ Ð·Ð°ÐºÐ°Ð·Ð¾Ð²?",
        
        # Ð‘Ð°Ð»Ð°Ð½Ñ
        "ÐºÐ°Ðº Ð¿Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ?",
        "ÐºÐ°ÐºÐ¸Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼ Ð¿Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ?",
        "Ð³Ð´Ðµ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ ÑÑ‡ÐµÑ‚?",
        "ÐºÐ°Ðº Ð¿Ñ€Ð¸Ð²ÑÐ·Ð°Ñ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ñƒ?",
        
        # ÐœÐ¾Ñ‚Ð¾Ñ‡Ð°ÑÑ‹
        "Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ð¼Ð¾Ñ‚Ð¾Ñ‡Ð°ÑÑ‹?",
        "Ñ‡Ñ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÑŽÑ‚ Ð¼Ð¾Ñ‚Ð¾Ñ‡Ð°ÑÑ‹ Ð² Ñ‚Ð°Ñ€Ð¸Ñ„Ðµ?",
        "ÐºÐ°Ðº ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð¾Ð¿Ð»Ð°Ñ‚Ð° Ð·Ð° Ð²Ñ€ÐµÐ¼Ñ?",
        "Ð·Ð°Ñ‡ÐµÐ¼ Ð²Ð²ÐµÐ»Ð¸ Ð¾Ð¿Ð»Ð°Ñ‚Ñƒ Ð·Ð° Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹?",
        
        # Ð¢Ð°ÐºÑÐ¾Ð¼ÐµÑ‚Ñ€
        "ÐºÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ Ñ‚Ð°ÐºÑÐ¾Ð¼ÐµÑ‚Ñ€Ð¾Ð¼?",
        "ÐºÐ°Ðº Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ñ‚Ð°ÐºÑÐ¾Ð¼ÐµÑ‚Ñ€Ð¾Ð¼?",
        "ÐºÐ¾Ð³Ð´Ð° Ð½Ð°Ð¶Ð¸Ð¼Ð°Ñ‚ÑŒ Ð¿Ð¾ÐµÑ…Ð°Ð»Ð¸ Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ?",
        "ÐºÐ°Ðº Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒ Ð·Ð°ÐºÐ°Ð· Ð² Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸?",
        
        # ÐŸÑ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ
        "Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ?",
        "Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð½Ðµ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ",
        "ÐºÐ°Ðº Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ aparu?",
        "Ð¼Ð¾Ð¶ÐµÑ‚ Ð»Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° gps?"
    ]
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ
    results = []
    for i, query in enumerate(test_queries, 1):
        print(f"{i:2d}. Ð—Ð°Ð¿Ñ€Ð¾Ñ: '{query}'")
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
        result = enhance_classification_with_morphology(query, kb_data)
        
        if result.get('matched_item'):
            matched_item = result['matched_item']
            confidence = result.get('confidence', 0)
            language = result.get('language', 'ru')
            
            print(f"    âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ!")
            print(f"    ðŸ“Š Confidence: {confidence:.2f}")
            print(f"    ðŸŒ Language: {language}")
            print(f"    â“ Question: {matched_item.get('question', '')[:50]}...")
            print(f"    ðŸ’¬ Answer: {matched_item.get('answer', '')[:80]}...")
            
            results.append({
                'query': query,
                'found': True,
                'confidence': confidence,
                'language': language,
                'question': matched_item.get('question', ''),
                'answer_length': len(matched_item.get('answer', ''))
            })
        else:
            print(f"    âŒ Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
            results.append({
                'query': query,
                'found': False,
                'confidence': 0,
                'language': result.get('language', 'ru')
            })
        
        print()
    
    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    print("ðŸ“Š Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð¯")
    print("=" * 60)
    
    total_queries = len(results)
    found_queries = sum(1 for r in results if r['found'])
    success_rate = (found_queries / total_queries) * 100
    
    print(f"Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²: {total_queries}")
    print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹: {found_queries}")
    print(f"ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ ÑƒÑÐ¿ÐµÑ…Ð°: {success_rate:.1f}%")
    
    if found_queries > 0:
        avg_confidence = sum(r['confidence'] for r in results if r['found']) / found_queries
        print(f"Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {avg_confidence:.2f}")
        
        # Ð¯Ð·Ñ‹ÐºÐ¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        ru_count = sum(1 for r in results if r.get('language') == 'ru')
        kz_count = sum(1 for r in results if r.get('language') == 'kz')
        print(f"Ð ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº: {ru_count}")
        print(f"ÐšÐ°Ð·Ð°Ñ…ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº: {kz_count}")
    
    print()
    
    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
    failed_queries = [r for r in results if not r['found']]
    if failed_queries:
        print("âŒ Ð—ÐÐŸÐ ÐžÐ¡Ð« Ð‘Ð•Ð— Ð¡ÐžÐ’ÐŸÐÐ”Ð•ÐÐ˜Ð™:")
        for r in failed_queries[:5]:  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 5
            print(f"  - '{r['query']}'")
        if len(failed_queries) > 5:
            print(f"  ... Ð¸ ÐµÑ‰Ðµ {len(failed_queries) - 5}")

def test_morphological_features():
    """Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
    print("\nðŸ”¬ Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð• ÐœÐžÐ Ð¤ÐžÐ›ÐžÐ“Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð¥ Ð¤Ð£ÐÐšÐ¦Ð˜Ð™")
    print("=" * 60)
    
    # Ð¢ÐµÑÑ‚ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    test_texts = [
        "Ð§Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ ÐÐÐ¦Ð•ÐÐšÐ???",
        "ÐšÐ°Ðº Ð¿Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ!",
        "ÐŸÑ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚...",
        "ÐœÐ¾Ñ‚Ð¾Ñ‡Ð°ÑÑ‹ - ÑÑ‚Ð¾ Ñ‡Ñ‚Ð¾?"
    ]
    
    print("ðŸ“ ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°:")
    for text in test_texts:
        normalized = enhanced_analyzer.normalize_text(text)
        print(f"  '{text}' -> '{normalized}'")
    
    print()
    
    # Ð¢ÐµÑÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾ÑÐ½Ð¾Ð²Ñ‹ ÑÐ»Ð¾Ð²Ð°
    test_words = [
        "Ð½Ð°Ñ†ÐµÐ½ÐºÐ°", "Ð½Ð°Ñ†ÐµÐ½ÐºÐ¸", "Ð½Ð°Ñ†ÐµÐ½ÐºÑƒ",
        "ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚", "ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚Ð°", "ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚Ð¾Ð¼",
        "Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ°", "Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸", "Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÑƒ",
        "Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ", "Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»Ñ", "Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŽ"
    ]
    
    print("ðŸ”¤ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾ÑÐ½Ð¾Ð²Ñ‹ ÑÐ»Ð¾Ð²Ð°:")
    for word in test_words:
        stem = enhanced_analyzer.get_word_stem(word)
        print(f"  '{word}' -> '{stem}'")
    
    print()
    
    # Ð¢ÐµÑÑ‚ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
    test_queries = [
        "Ð½Ð°Ñ†ÐµÐ½ÐºÐ°",
        "Ñ‚Ð°Ñ€Ð¸Ñ„ ÐºÐ¾Ð¼Ñ„Ð¾Ñ€Ñ‚",
        "Ð¿Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ"
    ]
    
    print("ðŸ”„ Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°:")
    for query in test_queries:
        expanded = enhanced_analyzer.expand_query(query)
        print(f"  '{query}' -> {expanded[:5]}...")  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 5 Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð²

if __name__ == "__main__":
    test_morphological_analysis()
    test_morphological_features()
