#!/usr/bin/env python3
"""
üß† –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º
–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Å –æ–∫–æ–Ω—á–∞–Ω–∏—è–º–∏ –∏ —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ —Å–ª–æ–≤
"""

import json
import logging
import re
from typing import Dict, List, Any, Optional
from datetime import datetime
from morphological_analyzer import morphological_analyzer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MorphologicalSearchClient:
    def __init__(self, knowledge_base_path: str = "senior_ai_knowledge_base.json"):
        self.knowledge_base_path = knowledge_base_path
        self.knowledge_base = []
        self.morphological_analyzer = morphological_analyzer
        
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        self.stop_words = set([
            '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞', '—Ç–∞–∫', '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞', '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ', '–º–Ω–µ', '–±—ã–ª–æ', '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç', '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞', '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥', '–ª–∏', '–µ—Å–ª–∏', '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ', '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å', '—É–∂', '–≤–∞–º', '–≤–µ–¥—å', '—Ç–∞–º', '–ø–æ—Ç–æ–º', '—Å–µ–±—è', '–Ω–∏—á–µ–≥–æ', '–µ–π', '–º–æ–∂–µ—Ç', '–æ–Ω–∏', '—Ç—É—Ç', '–≥–¥–µ', '–µ—Å—Ç—å', '–Ω–∞–¥–æ', '–Ω–µ–π', '–¥–ª—è', '–º—ã', '—Ç–µ–±—è', '–∏—Ö', '—á–µ–º', '–±—ã–ª–∞', '—Å–∞–º', '—á—Ç–æ–±', '–±–µ–∑', '–±—É–¥—Ç–æ', '—á–µ–≥–æ', '—Ä–∞–∑', '—Ç–æ–∂–µ', '—Å–µ–±–µ', '–ø–æ–¥', '–±—É–¥–µ—Ç', '–∂', '—Ç–æ–≥–¥–∞', '–∫—Ç–æ', '—ç—Ç–æ—Ç', '—Ç–æ–≥–æ', '–ø–æ—Ç–æ–º—É', '—ç—Ç–æ–≥–æ', '–∫–∞–∫–æ–π', '—Å–æ–≤—Å–µ–º', '–Ω–∏–º', '–∑–¥–µ—Å—å', '—ç—Ç–æ–º', '–æ–¥–∏–Ω', '–ø–æ—á—Ç–∏', '–º–æ–π', '—Ç–µ–º', '—á—Ç–æ–±—ã', '–Ω–µ–µ', '—Å–µ–π—á–∞—Å', '–±—ã–ª–∏', '–∫—É–¥–∞', '–∑–∞—á–µ–º', '–≤—Å–µ—Ö', '–Ω–∏–∫–æ–≥–¥–∞', '–º–æ–∂–Ω–æ', '–ø—Ä–∏', '–Ω–∞–∫–æ–Ω–µ—Ü', '–¥–≤–∞', '–æ–±', '–¥—Ä—É–≥–æ–π', '—Ö–æ—Ç—å', '–ø–æ—Å–ª–µ', '–Ω–∞–¥', '–±–æ–ª—å—à–µ', '—Ç–æ—Ç', '—á–µ—Ä–µ–∑', '—ç—Ç–∏', '–Ω–∞—Å', '–ø—Ä–æ', '–≤—Å–µ–≥–æ', '–Ω–∏—Ö', '–∫–∞–∫–∞—è', '–º–Ω–æ–≥–æ', '—Ä–∞–∑–≤–µ', '—Ç—Ä–∏', '—ç—Ç—É', '–º–æ—è', '–≤–ø—Ä–æ—á–µ–º', '—Ö–æ—Ä–æ—à–æ', '—Å–≤–æ—é', '—ç—Ç–æ–π', '–ø–µ—Ä–µ–¥', '–∏–Ω–æ–≥–¥–∞', '–ª—É—á—à–µ', '—á—É—Ç—å', '—Ç–æ–º', '–Ω–µ–ª—å–∑—è', '—Ç–∞–∫–æ–π', '–∏–º', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–∫–æ–Ω–µ—á–Ω–æ', '–≤—Å—é', '–º–µ–∂–¥—É'
        ])
        
        # –ü—Ä—è–º—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏
        self.direct_mappings = {
            # –ù–∞—Ü–µ–Ω–∫–∞
            '—á—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∞': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '—á—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∏': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '—á—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫—É': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '—á—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–æ–π': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–ø–æ—á–µ–º—É —Ç–∞–∫ –¥–æ—Ä–æ–≥–æ': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–æ—Ç–∫—É–¥–∞ –¥–æ–ø–ª–∞—Ç–∞': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–æ—Ç–∫—É–¥–∞ –¥–æ–ø–ª–∞—Ç—ã': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–æ—Ç–∫—É–¥–∞ –¥–æ–ø–ª–∞—Ç—É': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '—á—Ç–æ –∑–∞ –Ω–∞–¥–±–∞–≤–∫–∞': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '—á—Ç–æ –∑–∞ –Ω–∞–¥–±–∞–≤–∫–∏': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '—á—Ç–æ –∑–∞ –Ω–∞–¥–±–∞–≤–∫—É': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–ø–æ–≤—ã—à–∞—é—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–ø–æ–≤—ã—à–∞—é—â–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø–ª–∞—Ç–∞': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø–ª–∞—Ç—ã': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–Ω–∞–¥–±–∞–≤–∫–∞ –∫ —Ü–µ–Ω–µ': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–Ω–∞–¥–±–∞–≤–∫–∏ –∫ —Ü–µ–Ω–µ': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–ø–æ–≤—ã—à–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–ø–æ–≤—ã—à–µ–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–¥–æ–ø–ª–∞—Ç–∞ –≤ –∑–∞–∫–∞–∑–µ': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–¥–æ–ø–ª–∞—Ç—ã –≤ –∑–∞–∫–∞–∑–µ': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–ø—Ä–æ—Å–∞': '–Ω–∞—Ü–µ–Ω–∫–∞',
            '–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Å–ø—Ä–æ—Å–∞': '–Ω–∞—Ü–µ–Ω–∫–∞',
            
            # –î–æ—Å—Ç–∞–≤–∫–∞
            '–∫–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∫–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∫–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫–æ–π': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–æ—Å—ã–ª–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–æ—Å—ã–ª–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–æ—Å—ã–ª–∫–æ–π': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–≤—ã–∑–≤–∞—Ç—å –∫—É—Ä—å–µ—Ä–∞': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–≤—ã–∑–≤–∞—Ç—å –∫—É—Ä—å–µ—Ä–∞': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–≤—ã–∑–≤–∞—Ç—å –∫—É—Ä—å–µ—Ä–∞': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∑–∞–∫–∞–∑ –¥–æ—Å—Ç–∞–≤–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∑–∞–∫–∞–∑ –¥–æ—Å—Ç–∞–≤–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–∑–∞–∫–∞–∑ –¥–æ—Å—Ç–∞–≤–∫–æ–π': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–æ—Ñ–æ—Ä–º–∏—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–æ—Ñ–æ—Ä–º–∏—Ç—å –¥–æ—Å—Ç–∞–≤–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–≤—ã–∑–≤–∞—Ç—å –º–∞—à–∏–Ω—É –¥–ª—è –¥–æ—Å—Ç–∞–≤–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–≤—ã–∑–≤–∞—Ç—å –º–∞—à–∏–Ω—É –¥–ª—è –¥–æ—Å—Ç–∞–≤–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–ø–µ—Ä–µ–≤–æ–∑–∫–∞ –ø–æ—Å—ã–ª–∫–∏': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–ø–µ—Ä–µ–≤–æ–∑–∫–∞ –ø–æ—Å—ã–ª–∫—É': '–¥–æ—Å—Ç–∞–≤–∫–∞',
            
            # –ë–∞–ª–∞–Ω—Å
            '–∫–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å': '–±–∞–ª–∞–Ω—Å',
            '–∫–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å–∞': '–±–∞–ª–∞–Ω—Å',
            '–∫–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å—É': '–±–∞–ª–∞–Ω—Å',
            '–∫–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å–æ–º': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å —Å—á–µ—Ç': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å —Å—á–µ—Ç–∞': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å —Å—á–µ—Ç—É': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å —Å—á–µ—Ç–æ–º': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å –∫–æ—à–µ–ª–µ–∫': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å –∫–æ—à–µ–ª—å–∫–∞': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å –∫–æ—à–µ–ª—å–∫—É': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å –∫–æ—à–µ–ª—å–∫–æ–º': '–±–∞–ª–∞–Ω—Å',
            '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–æ–º': '–±–∞–ª–∞–Ω—Å',
            '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–∏—Ç—å —á–µ—Ä–µ–∑': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞': '–±–∞–ª–∞–Ω—Å',
            '–ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞': '–±–∞–ª–∞–Ω—Å',
            
            # –ö–æ–º—Ñ–æ—Ä—Ç
            '—á—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '—á—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç–∞': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '—á—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç—É': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '—á—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç–æ–º': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç –∫–ª–∞—Å—Å': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç–∞ –∫–ª–∞—Å—Å': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç —Ç–∞—Ä–∏—Ñ': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç–∞ —Ç–∞—Ä–∏—Ñ': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç –∫–ª–∞—Å—Å –º–∞—à–∏–Ω—ã': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç–∞ –∫–ª–∞—Å—Å –º–∞—à–∏–Ω—ã': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—å': '–∫–æ–º—Ñ–æ—Ä—Ç',
            '–∫–æ–º—Ñ–æ—Ä—Ç–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—å': '–∫–æ–º—Ñ–æ—Ä—Ç',
            
            # –ú–æ—Ç–æ—á–∞—Å—ã
            '—á—Ç–æ —Ç–∞–∫–æ–µ –º–æ—Ç–æ—á–∞—Å—ã': '–º–æ—Ç–æ—á–∞—Å—ã',
            '—á—Ç–æ —Ç–∞–∫–æ–µ –º–æ—Ç–æ—á–∞—Å–æ–≤': '–º–æ—Ç–æ—á–∞—Å—ã',
            '—á—Ç–æ —Ç–∞–∫–æ–µ –º–æ—Ç–æ—á–∞—Å–∞–º': '–º–æ—Ç–æ—á–∞—Å—ã',
            '—á—Ç–æ —Ç–∞–∫–æ–µ –º–æ—Ç–æ—á–∞—Å–∞–º–∏': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–≤—Ä–µ–º—è –ø–æ–µ–∑–¥–∫–∏': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–≤—Ä–µ–º–µ–Ω–∏ –ø–æ–µ–∑–¥–∫–∏': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–≤—Ä–µ–º–µ–Ω–∏ –ø–æ–µ–∑–¥–∫—É': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–æ–ø–ª–∞—Ç–∞ –∑–∞ –≤—Ä–µ–º—è': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–æ–ø–ª–∞—Ç–∞ –∑–∞ –≤—Ä–µ–º–µ–Ω–∏': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–ø–æ–º–∏–Ω—É—Ç–Ω–∞—è –æ–ø–ª–∞—Ç–∞': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–ø–æ–º–∏–Ω—É—Ç–Ω—ã–µ –æ–ø–ª–∞—Ç—ã': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–≤—Ä–µ–º—è –≤ —Ç–∞—Ä–∏—Ñ–µ': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–≤—Ä–µ–º–µ–Ω–∏ –≤ —Ç–∞—Ä–∏—Ñ–µ': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–¥–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–∫–∞–∑—ã': '–º–æ—Ç–æ—á–∞—Å—ã',
            '–¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤': '–º–æ—Ç–æ—á–∞—Å—ã',
            
            # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ gps': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ gps': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤—ã–ª–µ—Ç–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤—ã–ª–µ—Ç–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∑–∞–≤–∏—Å–∞–µ—Ç': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ'
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._load_knowledge_base()
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.quality_metrics = {
            'total_requests': 0,
            'successful_matches': 0,
            'high_confidence_matches': 0,
            'category_distribution': {},
            'avg_response_time': 0.0
        }
    
    def _load_knowledge_base(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        try:
            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                self.knowledge_base = json.load(f)
            logger.info(f"‚úÖ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(self.knowledge_base)} –∑–∞–ø–∏—Å–µ–π")
        except FileNotFoundError:
            logger.error(f"‚ùå –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.knowledge_base_path}")
            self.knowledge_base = []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
            self.knowledge_base = []
    
    def normalize_text_morphological(self, text: str) -> str:
        """–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words = text.split()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏
        normalized_words = []
        for word in words:
            if word not in self.stop_words and len(word) > 2:
                normalized_word = self.morphological_analyzer.normalize_word(word)
                normalized_words.append(normalized_word)
        
        return ' '.join(normalized_words)
    
    def expand_query_morphological(self, query: str) -> List[str]:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        expanded_queries = self.morphological_analyzer.expand_query(query)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä—è–º—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏
        normalized_query = self.normalize_text_morphological(query)
        for mapping_key, mapped_value in self.direct_mappings.items():
            if mapping_key in normalized_query:
                expanded_queries.append(mapped_value)
                expanded_queries.append(self.normalize_text_morphological(mapped_value))
        
        return list(set(expanded_queries))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    def calculate_similarity_morphological(self, text1: str, text2: str) -> float:
        """–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±–∞ —Ç–µ–∫—Å—Ç–∞
        words1 = set(self.normalize_text_morphological(text1).split())
        words2 = set(self.normalize_text_morphological(text2).split())
        
        if not words1 or not words2:
            return 0.0
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        base_similarity = len(intersection) / len(union) if union else 0.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        bonus = 0.0
        for word1 in words1:
            for word2 in words2:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è—é—Ç—Å—è –ª–∏ —Å–ª–æ–≤–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏
                if self.morphological_analyzer.normalize_word(word1) == self.morphological_analyzer.normalize_word(word2):
                    bonus += 0.3
        
        # –ë–æ–Ω—É—Å –∑–∞ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        for word1 in words1:
            for word2 in words2:
                if word1 in word2 or word2 in word1:
                    bonus += 0.1
        
        return min(base_similarity + bonus, 1.0)
    
    def find_direct_mapping_morphological(self, query: str) -> Optional[str]:
        """–ò—â–µ—Ç –ø—Ä—è–º–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏"""
        normalized_query = self.normalize_text_morphological(query)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        for mapping_key, mapping_value in self.direct_mappings.items():
            if mapping_key in normalized_query:
                return mapping_value
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        for mapping_key, mapping_value in self.direct_mappings.items():
            mapping_words = mapping_key.split()
            query_words = normalized_query.split()
            
            # –ï—Å–ª–∏ –≤—Å–µ —Å–ª–æ–≤–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –µ—Å—Ç—å –≤ –∑–∞–ø—Ä–æ—Å–µ
            if all(word in query_words for word in mapping_words):
                return mapping_value
        
        return None
    
    def search_morphological(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫"""
        start_time = datetime.now()
        
        results = []
        
        # –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏
        expanded_queries = self.expand_query_morphological(query)
        
        for idx, item in enumerate(self.knowledge_base):
            max_score = 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –≤–æ–ø—Ä–æ—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –≤–µ—Å–æ–º
            for expanded_query in expanded_queries:
                question_similarity = self.calculate_similarity_morphological(expanded_query, item['question'])
                max_score = max(max_score, question_similarity * 5.0)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ —Å –≤—ã—Å–æ–∫–∏–º –≤–µ—Å–æ–º
            for variation in item.get('variations', []):
                for expanded_query in expanded_queries:
                    variation_similarity = self.calculate_similarity_morphological(expanded_query, variation)
                    max_score = max(max_score, variation_similarity * 4.0)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –≤–µ—Å–æ–º
            query_words = set()
            for expanded_query in expanded_queries:
                query_words.update(self.normalize_text_morphological(expanded_query).split())
            
            keyword_matches = 0
            for keyword in item.get('keywords', []):
                keyword_normalized = self.normalize_text_morphological(keyword)
                if keyword_normalized in query_words:
                    keyword_matches += 1
            
            if keyword_matches > 0:
                max_score = max(max_score, keyword_matches * 3.0)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
            for expanded_query in expanded_queries:
                answer_similarity = self.calculate_similarity_morphological(expanded_query, item['answer'])
                max_score = max(max_score, answer_similarity * 2.0)
            
            if max_score > 0:
                results.append({
                    'id': item.get('id', idx),
                    'question': item['question'],
                    'answer': item['answer'],
                    'category': item.get('category', 'general'),
                    'confidence': min(max_score / 7.0, 1.0),
                    'keywords': item.get('keywords', []),
                    'variations': item.get('variations', []),
                    'metadata': item.get('metadata', {})
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é score
        results.sort(key=lambda x: x['confidence'], reverse=True)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        response_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"üß† –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {response_time:.3f} —Å–µ–∫—É–Ω–¥")
        
        return results[:top_k]
    
    def get_enhanced_answer(self, question: str) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        start_time = datetime.now()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.quality_metrics['total_requests'] += 1
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        results = self.search_morphological(question, top_k=3)
        
        response_time = (datetime.now() - start_time).total_seconds()
        self.quality_metrics['avg_response_time'] = (
            (self.quality_metrics['avg_response_time'] * (self.quality_metrics['total_requests'] - 1) + response_time) 
            / self.quality_metrics['total_requests']
        )
        
        if not results:
            return "–ù—É–∂–Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        best_result = results[0]
        
        if best_result['confidence'] >= 0.3:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self.quality_metrics['successful_matches'] += 1
            if best_result['confidence'] >= 0.6:
                self.quality_metrics['high_confidence_matches'] += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            category = best_result['category']
            self.quality_metrics['category_distribution'][category] = self.quality_metrics['category_distribution'].get(category, 0) + 1
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç
            return best_result['answer']
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏–µ
            return "–ù—É–∂–Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
    
    def get_statistics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã"""
        base_metrics = {
            **self.quality_metrics,
            'total_knowledge_records': len(self.knowledge_base),
            'morphological_analysis': True
        }
        
        if self.quality_metrics['total_requests'] == 0:
            return base_metrics
        
        success_rate = self.quality_metrics['successful_matches'] / self.quality_metrics['total_requests']
        high_confidence_rate = self.quality_metrics['high_confidence_matches'] / self.quality_metrics['total_requests']
        
        return {
            **base_metrics,
            'success_rate': success_rate,
            'high_confidence_rate': high_confidence_rate
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
morphological_search_client = MorphologicalSearchClient()

def get_enhanced_answer(question: str) -> str:
    """–û—Å–Ω–æ–≤–Ω–æ–π API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å main.py"""
    return morphological_search_client.get_enhanced_answer(question)

def get_morphological_statistics() -> Dict[str, Any]:
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    return morphological_search_client.get_statistics()

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É
    client = MorphologicalSearchClient()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = client.get_statistics()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞:")
    print(f"   –ó–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ: {stats['total_knowledge_records']}")
    print(f"   –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: {'‚úÖ' if stats['morphological_analysis'] else '‚ùå'}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    test_questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∏?",  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ
        "–ü–æ—á–µ–º—É —Ç–∞–∫ –¥–æ—Ä–æ–≥–æ?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç–∞—Ä–∏—Ñ –∫–æ–º—Ñ–æ—Ä—Ç–∞?",  # –†–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂
        "–ö–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å?",
        "–ö–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–æ—Ç–æ—á–∞—Å—ã?",
        "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç",
        "–û—Ç–∫—É–¥–∞ –¥–æ–ø–ª–∞—Ç—ã –≤ –∑–∞–∫–∞–∑–µ?",  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ
        "–ö–∞–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–æ—Å—ã–ª–∫—É?",
        "–ü–æ–≤—ã—à–∞—é—â–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã"  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ
    ]
    
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã:")
    successful_answers = 0
    
    for question in test_questions:
        answer = client.get_enhanced_answer(question)
        if answer != "–ù—É–∂–Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è":
            successful_answers += 1
        print(f"‚ùì {question}")
        print(f"‚úÖ {answer[:100]}...")
        print()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    final_stats = client.get_statistics()
    print(f"\nüìà –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã:")
    print(f"   –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {final_stats.get('success_rate', 0):.1%}")
    print(f"   –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {final_stats.get('high_confidence_rate', 0):.1%}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {final_stats.get('avg_response_time', 0):.3f}s")
    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Ç–µ—Å—Ç–µ: {successful_answers}/{len(test_questions)}")
