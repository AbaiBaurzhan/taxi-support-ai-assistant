#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è APARU LLM
–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Tuple

class ImprovedContextSearch:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞"""
        
        # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
        self.knowledge_base = []
        
        # –°–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–≤—è–∑–µ–π
        self.context_mappings = self._create_context_mappings()
        
        # –°–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        self.question_keywords = {}
        
    def _create_context_mappings(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–≤—è–∑–µ–π"""
        
        return {
            # –ì—Ä—É–ø–ø—ã —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–æ–Ω—è—Ç–∏–π
            "pricing": {
                "keywords": ["—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Ä–∞—Å—Ü–µ–Ω–∫–∞", "—Ç–∞—Ä–∏—Ñ", "–Ω–∞—Ü–µ–Ω–∫–∞", "–¥–æ—Ä–æ–≥–æ", "–¥–µ—à–µ–≤–æ", "–æ–ø–ª–∞—Ç–∞", "–ø–ª–∞—Ç–µ–∂", "—Å—Ç–æ–∏—Ç", "—Å–∫–æ–ª—å–∫–æ"],
                "contexts": ["—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "–ø–æ—á–µ–º—É –¥–æ—Ä–æ–≥–æ", "–æ—Ç–∫—É–¥–∞ —Ü–µ–Ω–∞", "—á—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Ü–µ–Ω–∫–∞", "–∫–∞–∫ —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ü–µ–Ω–∞", "–ø–æ—á–µ–º—É —Ç–∞–∫ –¥–æ—Ä–æ–≥–æ"]
            },
            "payment": {
                "keywords": ["–ø–æ–ø–æ–ª–Ω–∏—Ç—å", "–±–∞–ª–∞–Ω—Å", "—Å—á–µ—Ç", "–¥–µ–Ω—å–≥–∏", "–æ–ø–ª–∞—Ç–∏—Ç—å", "–ø–ª–∞—Ç–µ–∂", "–∫–æ—à–µ–ª–µ–∫", "–∫–∞—Ä—Ç–∞", "–∑–∞–ø–ª–∞—Ç–∏—Ç—å", "–≤–Ω–µ—Å—Ç–∏"],
                "contexts": ["–∫–∞–∫ –∑–∞–ø–ª–∞—Ç–∏—Ç—å", "–≥–¥–µ –ø–æ–ø–æ–ª–Ω–∏—Ç—å", "–∫–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –¥–µ–Ω—å–≥–∏", "–∫–∞–∫ –≤–Ω–µ—Å—Ç–∏ —Å—Ä–µ–¥—Å—Ç–≤–∞", "–∫–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å"]
            },
            "booking": {
                "keywords": ["–∑–∞–∫–∞–∑–∞—Ç—å", "–≤—ã–∑–≤–∞—Ç—å", "–∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å", "–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π", "–∑–∞—Ä–∞–Ω–µ–µ", "–≤—Ä–µ–º—è", "–∑–∞–∫–∞–∑"],
                "contexts": ["–∫–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å —Ç–∞–∫—Å–∏", "–º–æ–∂–Ω–æ –ª–∏ –∑–∞—Ä–∞–Ω–µ–µ", "–∫–∞–∫ –∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å", "–∫–æ–≥–¥–∞ –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å", "–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–∫–∞–∑"]
            },
            "driver": {
                "keywords": ["–≤–æ–¥–∏—Ç–µ–ª—å", "—Ä–∞–±–æ—Ç–∞—Ç—å", "–∑–∞–∫–∞–∑—ã", "–ø–∞—Ä—Ç–Ω–µ—Ä", "—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è", "—Ç–∞–∫—Å–æ–º–µ—Ç—Ä", "—Ä–∞–±–æ—Ç–∞"],
                "contexts": ["–∫–∞–∫ —Å—Ç–∞—Ç—å –≤–æ–¥–∏—Ç–µ–ª–µ–º", "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å", "–∫–∞–∫ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–∞–∫–∞–∑—ã", "–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–∞–∫—Å–æ–º–µ—Ç—Ä–æ–º"]
            },
            "delivery": {
                "keywords": ["–¥–æ—Å—Ç–∞–≤–∫–∞", "–∫—É—Ä—å–µ—Ä", "—Ç–æ–≤–∞—Ä", "–≤–µ—â–∏", "–¥–æ–∫—É–º–µ–Ω—Ç—ã", "–ø–æ—Å—ã–ª–∫–∞", "–¥–æ—Å—Ç–∞–≤–∏—Ç—å"],
                "contexts": ["–∫–∞–∫ –∑–∞–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É", "–∫–∞–∫ –¥–æ—Å—Ç–∞–≤–∏—Ç—å", "–∫—É—Ä—å–µ—Ä—Å–∫–∞—è —Å–ª—É–∂–±–∞", "–¥–æ—Å—Ç–∞–≤–∫–∞ —Ç–æ–≤–∞—Ä–∞"]
            },
            "technical": {
                "keywords": ["–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–ø—Ä–æ–±–ª–µ–º–∞", "–æ—à–∏–±–∫–∞", "–∑–∞–≤–∏—Å–∞–µ—Ç", "–Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è", "–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è"],
                "contexts": ["–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "—á—Ç–æ –¥–µ–ª–∞—Ç—å", "–∫–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å", "–ø—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º"]
            },
            "comfort": {
                "keywords": ["–∫–æ–º—Ñ–æ—Ä—Ç", "–ø—Ä–µ–º–∏—É–º", "–∫–ª–∞—Å—Å", "–º–∞—à–∏–Ω–∞", "—Ç–∞—Ä–∏—Ñ", "–ª—É—á—à–µ", "–Ω–æ–≤–∞—è"],
                "contexts": ["—á—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º—Ñ–æ—Ä—Ç", "–∫–æ–º—Ñ–æ—Ä—Ç –∫–ª–∞—Å—Å", "–ø—Ä–µ–º–∏—É–º —Ç–∞–∫—Å–∏", "–Ω–æ–≤–∞—è –º–∞—à–∏–Ω–∞"]
            },
            "motohours": {
                "keywords": ["–º–æ—Ç–æ—á–∞—Å—ã", "–≤—Ä–µ–º—è", "–ø–æ–µ–∑–¥–∫–∞", "–æ–ø–ª–∞—Ç–∞", "—Ç–∞—Ä–∏—Ñ", "—Å—á–∏—Ç–∞—é—Ç", "–º–∏–Ω—É—Ç—ã"],
                "contexts": ["—á—Ç–æ —Ç–∞–∫–æ–µ –º–æ—Ç–æ—á–∞—Å—ã", "–æ–ø–ª–∞—Ç–∞ –∑–∞ –≤—Ä–µ–º—è", "—Å—á–∏—Ç–∞—é—Ç –≤—Ä–µ–º—è", "–≤—Ä–µ–º—è –ø–æ–µ–∑–¥–∫–∏"]
            }
        }
    
    def load_knowledge_base(self, kb_file: str = "database_Aparu/BZ.txt"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        
        print("üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...")
        
        # –ß–∏—Ç–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –±–∞–∑—É
        with open(kb_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü–∞—Ä—Å–∏–º –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã
        sections = content.split('- question:')
        
        for section in sections[1:]:
            lines = section.strip().split('\n')
            if len(lines) >= 2:
                question = lines[0].strip()
                answer = '\n'.join(lines[1:]).strip()
                
                # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                kb_entry = {
                    "question": question,
                    "answer": answer,
                    "keywords": self._extract_keywords(question),
                    "category": self._categorize_question(question),
                    "contexts": self._generate_contexts(question),
                    "similarity_score": 0.0
                }
                
                self.knowledge_base.append(kb_entry)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
                self.question_keywords[question.lower()] = kb_entry["keywords"]
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.knowledge_base)} –∑–∞–ø–∏—Å–µ–π")
        return self.knowledge_base
    
    def _extract_keywords(self, question: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞"""
        
        # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            "—á—Ç–æ", "–∫–∞–∫", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", "–º–æ–∂–Ω–æ", "–ª–∏", "—ç—Ç–æ", "—Ç–∞–∫–æ–µ",
            "–æ–∑–Ω–∞—á–∞–µ—Ç", "–∑–Ω–∞—á–∏—Ç", "–µ—Å—Ç—å", "–±—ã—Ç—å", "–¥–µ–ª–∞—Ç—å", "—Å–¥–µ–ª–∞—Ç—å", "—É–∑–Ω–∞—Ç—å", "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å",
            "–Ω–∞–π—Ç–∏", "–ø–æ–ª—É—á–∏—Ç—å", "–≤–∑—è—Ç—å", "–¥–∞—Ç—å", "—Å–∫–∞–∑–∞—Ç—å", "–æ–±—ä—è—Å–Ω–∏—Ç—å", "–º–Ω–µ", "–º–Ω–µ", "—è"
        }
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words = re.findall(r'\b\w+\b', question.lower())
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        
        return keywords
    
    def _categorize_question(self, question: str) -> str:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
        
        question_lower = question.lower()
        
        for category, data in self.context_mappings.items():
            if any(keyword in question_lower for keyword in data["keywords"]):
                return category
        
        return "general"
    
    def _generate_contexts(self, question: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤–æ–ø—Ä–æ—Å–∞"""
        
        contexts = [question]
        question_lower = question.lower()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è
        for category, data in self.context_mappings.items():
            if any(keyword in question_lower for keyword in data["keywords"]):
                contexts.extend(data["contexts"])
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω–æ–Ω–∏–º–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        synonyms = {
            "—á—Ç–æ —Ç–∞–∫–æ–µ": ["—á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç", "—á—Ç–æ —ç—Ç–æ", "—á—Ç–æ –∑–Ω–∞—á–∏—Ç", "—á—Ç–æ –∑–∞"],
            "–∫–∞–∫": ["–∫–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º", "–∫–∞–∫ –∏–º–µ–Ω–Ω–æ", "–∫–∞–∫ –º–æ–∂–Ω–æ", "–∫–∞–∫ –Ω—É–∂–Ω–æ"],
            "–≥–¥–µ": ["–≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ", "–≥–¥–µ –Ω–∞–π—Ç–∏", "–≥–¥–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å", "–≥–¥–µ –∏—Å–∫–∞—Ç—å"],
            "–ø–æ—á–µ–º—É": ["–∑–∞—á–µ–º", "–æ—Ç–∫—É–¥–∞", "–∏–∑-–∑–∞ —á–µ–≥–æ", "–ø–æ –∫–∞–∫–æ–π –ø—Ä–∏—á–∏–Ω–µ"],
            "–º–æ–∂–Ω–æ –ª–∏": ["–≤–æ–∑–º–æ–∂–Ω–æ –ª–∏", "—Ä–µ–∞–ª—å–Ω–æ –ª–∏", "–ø–æ–ª—É—á–∏—Ç—Å—è –ª–∏", "—É–¥–∞—Å—Ç—Å—è –ª–∏"]
        }
        
        for original, alternatives in synonyms.items():
            if original in question_lower:
                for alt in alternatives:
                    new_context = question_lower.replace(original, alt)
                    if new_context not in contexts:
                        contexts.append(new_context.capitalize())
        
        return list(set(contexts))
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
        
        query_lower = query.lower()
        results = []
        
        for item in self.knowledge_base:
            score = 0.0
            
            # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞
            if item['question'].lower() in query_lower:
                score += 10.0
            
            # 2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            for keyword in item['keywords']:
                if keyword.lower() in query_lower:
                    score += 2.0
            
            # 3. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤
            for context in item['contexts']:
                if context.lower() in query_lower:
                    score += 1.5
            
            # 4. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_keywords = self.context_mappings.get(item['category'], {}).get('keywords', [])
            for keyword in category_keywords:
                if keyword.lower() in query_lower:
                    score += 1.0
            
            # 5. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ
            answer_words = set(item['answer'].lower().split())
            query_words = set(query_lower.split())
            answer_overlap = len(answer_words & query_words)
            if answer_overlap > 0:
                score += answer_overlap * 0.5
            
            if score > 0:
                item_copy = item.copy()
                item_copy['similarity_score'] = score
                results.append(item_copy)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        results.sort(key=lambda x: x['similarity_score'], reverse=True)
        return results[:top_k]
    
    def get_contextual_answer(self, query: str) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å"""
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø–∏—Å–∏
        results = self.search(query, top_k=3)
        
        if not results:
            return {
                "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.",
                "confidence": 0.0,
                "source": "fallback"
            }
        
        # –ë–µ—Ä–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        best_match = results[0]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = min(best_match["similarity_score"] / 10.0, 1.0)
        
        if confidence > 0.7:
            # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç
            return {
                "answer": best_match["answer"],
                "confidence": confidence,
                "source": "exact_match",
                "matched_question": best_match["question"],
                "category": best_match["category"]
            }
        elif confidence > 0.3:
            # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            return {
                "answer": best_match["answer"],
                "confidence": confidence,
                "source": "contextual_match",
                "matched_question": best_match["question"],
                "category": best_match["category"]
            }
        else:
            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–∏–π –æ—Ç–≤–µ—Ç
            return {
                "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ?",
                "confidence": confidence,
                "source": "low_confidence",
                "suggestions": [r["question"] for r in results[:3]]
            }

def test_improved_search():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    improved_search = ImprovedContextSearch()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
    improved_search.load_knowledge_base()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–ü–æ—á–µ–º—É —Ç–∞–∫ –¥–æ—Ä–æ–≥–æ?",
        "–ö–∞–∫ –∑–∞–ø–ª–∞—Ç–∏—Ç—å –∑–∞ –ø–æ–µ–∑–¥–∫—É?",
        "–ú–æ–∂–Ω–æ –ª–∏ –∑–∞–∫–∞–∑–∞—Ç—å –∑–∞—Ä–∞–Ω–µ–µ?",
        "–ö–∞–∫ —Å—Ç–∞—Ç—å –≤–æ–¥–∏—Ç–µ–ª–µ–º?",
        "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è",
        "–ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –Ω–∞—Ü–µ–Ω–∫–∞?",
        "–ì–¥–µ –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É?",
        "–ö–∞–∫ –¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å—ã–ª–∫—É?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º—Ñ–æ—Ä—Ç?",
        "–ü–æ—á–µ–º—É —Å—á–∏—Ç–∞—é—Ç –≤—Ä–µ–º—è?"
    ]
    
    print("\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    
    for query in test_queries:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {query}")
        
        result = improved_search.get_contextual_answer(query)
        
        print(f"üìù –û—Ç–≤–µ—Ç: {result['answer'][:100]}...")
        print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2f}")
        print(f"üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫: {result['source']}")
        
        if 'matched_question' in result:
            print(f"üîó –°–æ–≤–ø–∞–≤—à–∏–π –≤–æ–ø—Ä–æ—Å: {result['matched_question']}")
        
        if 'suggestions' in result:
            print(f"üí° –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {result['suggestions']}")

if __name__ == "__main__":
    print("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ APARU...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º
    test_improved_search()
    
    print("\n‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –≥–æ—Ç–æ–≤–∞!")
    print("üß† –¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç!")
