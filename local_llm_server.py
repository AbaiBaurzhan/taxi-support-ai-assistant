#!/usr/bin/env python3
"""
üöÄ APARU Local LLM Server
–ó–∞–ø—É—Å–∫–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π LLM —Å–µ—Ä–≤–µ—Ä —Å —Ç—É–Ω–Ω–µ–ª–µ–º –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
"""

import os
import sys
import subprocess
import time
import requests
import threading
from pathlib import Path

class LocalLLMServer:
    def __init__(self):
        self.llm_process = None
        self.tunnel_process = None
        self.tunnel_url = None
        
    def print_banner(self):
        print("=" * 70)
        print("ü§ñ APARU Local LLM Server")
        print("=" * 70)
        print("üì° –ó–∞–ø—É—Å–∫–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π LLM —Å –¥–æ—Å—Ç—É–ø–æ–º –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞")
        print("üåê –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Railway production")
        print("=" * 70)
        
    def check_ollama(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ Ollama"""
        print("üîç –ü—Ä–æ–≤–µ—Ä—è—é Ollama...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É
            result = subprocess.run(["ollama", "--version"], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print("‚úÖ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return True
            else:
                print("‚ùå Ollama –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print("‚ùå Ollama –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
            
    def install_ollama(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç Ollama"""
        print("üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é Ollama...")
        
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Ollama
            install_script = """
            curl -fsSL https://ollama.ai/install.sh | sh
            """
            
            result = subprocess.run(install_script, shell=True, 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                print("‚úÖ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏: {result.stderr}")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
            
    def download_model(self, model_name="llama2"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
        print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å {model_name}...")
        
        try:
            result = subprocess.run(["ollama", "pull", model_name], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {result.stderr}")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
            
    def start_ollama_server(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Ollama —Å–µ—Ä–≤–µ—Ä"""
        print("üöÄ –ó–∞–ø—É—Å–∫–∞—é Ollama —Å–µ—Ä–≤–µ—Ä...")
        
        try:
            self.llm_process = subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
            time.sleep(3)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            try:
                response = requests.get("http://localhost:11434/api/tags", timeout=5)
                if response.status_code == 200:
                    print("‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:11434")
                    return True
                else:
                    print("‚ùå Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç")
                    return False
            except requests.exceptions.RequestException:
                print("‚ùå Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
            return False
            
    def install_ngrok(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç ngrok"""
        print("üì¶ –ü—Ä–æ–≤–µ—Ä—è—é ngrok...")
        
        try:
            result = subprocess.run(["ngrok", "version"], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print("‚úÖ ngrok —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return True
            else:
                print("‚ùå ngrok –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print("‚ùå ngrok –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
            
    def start_tunnel(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç—É–Ω–Ω–µ–ª—å"""
        print("üåê –ó–∞–ø—É—Å–∫–∞—é —Ç—É–Ω–Ω–µ–ª—å...")
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º ngrok —Ç—É–Ω–Ω–µ–ª—å
            self.tunnel_process = subprocess.Popen(
                ["ngrok", "http", "11434", "--log=stdout"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
            time.sleep(3)
            
            # –ü–æ–ª—É—á–∞–µ–º URL —Ç—É–Ω–Ω–µ–ª—è
            try:
                response = requests.get("http://localhost:4040/api/tunnels", timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    tunnels = data.get("tunnels", [])
                    if tunnels:
                        self.tunnel_url = tunnels[0]["public_url"]
                        print(f"‚úÖ –¢—É–Ω–Ω–µ–ª—å –∑–∞–ø—É—â–µ–Ω: {self.tunnel_url}")
                        return True
                    else:
                        print("‚ùå –¢—É–Ω–Ω–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω")
                        return False
                else:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å URL —Ç—É–Ω–Ω–µ–ª—è")
                    return False
            except requests.exceptions.RequestException:
                print("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL —Ç—É–Ω–Ω–µ–ª—è")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ç—É–Ω–Ω–µ–ª—è: {e}")
            return False
            
    def test_llm(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç LLM —á–µ—Ä–µ–∑ —Ç—É–Ω–Ω–µ–ª—å"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É—é LLM...")
        
        if not self.tunnel_url:
            print("‚ùå –¢—É–Ω–Ω–µ–ª—å –Ω–µ –∑–∞–ø—É—â–µ–Ω")
            return False
            
        try:
            test_payload = {
                "model": "llama2",
                "prompt": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "max_tokens": 50
                }
            }
            
            response = requests.post(
                f"{self.tunnel_url}/api/generate",
                json=test_payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "")
                print(f"‚úÖ LLM –æ—Ç–≤–µ—á–∞–µ—Ç: {answer[:50]}...")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ LLM: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return False
            
    def update_railway_config(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è Railway"""
        print("‚öôÔ∏è –û–±–Ω–æ–≤–ª—è—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é...")
        
        if not self.tunnel_url:
            print("‚ùå –¢—É–Ω–Ω–µ–ª—å –Ω–µ –∑–∞–ø—É—â–µ–Ω")
            return False
            
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_content = f"""# APARU Local LLM Configuration
LLM_URL={self.tunnel_url}
LLM_MODEL=llama2
LLM_ENABLED=true
"""
        
        try:
            with open(".env.local", "w") as f:
                f.write(config_content)
            print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ .env.local")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return False
            
    def cleanup(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã"""
        print("\nüõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –ø—Ä–æ—Ü–µ—Å—Å—ã...")
        
        if self.tunnel_process:
            self.tunnel_process.terminate()
            print("‚èπÔ∏è –¢—É–Ω–Ω–µ–ª—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
        if self.llm_process:
            self.llm_process.terminate()
            print("‚èπÔ∏è Ollama –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
        self.print_banner()
        
        print("\nüéØ –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("1. üöÄ –ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ (Ollama + —Ç—É–Ω–Ω–µ–ª—å)")
        print("2. ü§ñ –¢–æ–ª—å–∫–æ Ollama")
        print("3. üåê –¢–æ–ª—å–∫–æ —Ç—É–Ω–Ω–µ–ª—å")
        print("4. üß™ –¢–µ—Å—Ç LLM")
        print("5. ‚öôÔ∏è –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
        print("0. ‚ùå –í—ã—Ö–æ–¥")
        
        choice = input("\nüëâ –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (0-5): ").strip()
        
        if choice == "1":
            # –ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
            if not self.check_ollama():
                if not self.install_ollama():
                    return
                    
            if not self.download_model():
                return
                
            if not self.start_ollama_server():
                return
                
            if not self.install_ngrok():
                print("üìù –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ngrok: https://ngrok.com/download")
                return
                
            if not self.start_tunnel():
                return
                
            if not self.test_llm():
                return
                
            if not self.update_railway_config():
                return
                
            print("\nüéâ –õ–æ–∫–∞–ª—å–Ω—ã–π LLM —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤!")
            print(f"üåê URL: {self.tunnel_url}")
            print("‚èπÔ∏è –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
            
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                pass
                
        elif choice == "2":
            # –¢–æ–ª—å–∫–æ Ollama
            if not self.check_ollama():
                if not self.install_ollama():
                    return
                    
            if not self.download_model():
                return
                
            if not self.start_ollama_server():
                return
                
            print("\n‚úÖ Ollama –∑–∞–ø—É—â–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ")
            print("üåê –î–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ http://localhost:11434")
            
        elif choice == "3":
            # –¢–æ–ª—å–∫–æ —Ç—É–Ω–Ω–µ–ª—å
            if not self.start_tunnel():
                return
                
            print(f"\n‚úÖ –¢—É–Ω–Ω–µ–ª—å –∑–∞–ø—É—â–µ–Ω: {self.tunnel_url}")
            
        elif choice == "4":
            # –¢–µ—Å—Ç
            if not self.test_llm():
                return
                
        elif choice == "5":
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            if not self.update_railway_config():
                return
                
        elif choice == "0":
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä!")
            
        self.cleanup()

def main():
    server = LocalLLMServer()
    server.run()

if __name__ == "__main__":
    main()
