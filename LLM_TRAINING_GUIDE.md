# ðŸ§  ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ LLM Ð½Ð° Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ Ñ‚Ð°ÐºÑÐ¸

## ðŸŽ¯ ÐŸÐ¾Ð´Ñ…Ð¾Ð´Ñ‹ Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ

### 1. **RAG (Retrieval Augmented Generation) - Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ!**
- ÐÐµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
- Ð‘Ñ‹ÑÑ‚Ñ€Ð¾ Ð²Ð½ÐµÐ´Ñ€ÑÐµÑ‚ÑÑ
- Ð›ÐµÐ³ÐºÐ¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ÑÑ
- Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ Ð»ÑŽÐ±Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»ÑŒÑŽ

### 2. **Fine-tuning**
- ÐŸÐ¾Ð»Ð½Ð¾Ðµ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
- Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¼Ð½Ð¾Ð³Ð¾ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
- Ð¡Ð»Ð¾Ð¶Ð½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑ‚ÑŒ
- Ð›ÑƒÑ‡ÑˆÐµ Ð´Ð»Ñ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð·Ð°Ð´Ð°Ñ‡

## ðŸš€ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚ Ñ RAG

### 1. **ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…**

#### Ð˜Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… SQLite:
```python
from knowledge_base_trainer import TaxiKnowledgeBase

kb = TaxiKnowledgeBase()
kb.load_from_database('support_database.db')
kb.build_embeddings_index()
kb.save_index('taxi_knowledge_index.pkl')
```

#### Ð˜Ð· CSV Ñ„Ð°Ð¹Ð»Ð°:
```python
kb = TaxiKnowledgeBase()
kb.load_from_csv('support_data.csv')
kb.build_embeddings_index()
kb.save_index('taxi_knowledge_index.pkl')
```

#### Ð˜Ð· JSON Ñ„Ð°Ð¹Ð»Ð°:
```python
kb = TaxiKnowledgeBase()
kb.load_from_json('support_data.json')
kb.build_embeddings_index()
kb.save_index('taxi_knowledge_index.pkl')
```

### 2. **Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…**

#### Ð”Ð»Ñ CSV:
```csv
question,answer,category,keywords
"Ð“Ð´Ðµ Ð¼Ð¾Ð¹ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ?","Ð’Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ ÐµÐ´ÐµÑ‚ Ðº Ð²Ð°Ð¼, Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ 5 Ð¼Ð¸Ð½ÑƒÑ‚","ride_status","Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ,ÑÑ‚Ð°Ñ‚ÑƒÑ,Ð¿Ð¾ÐµÐ·Ð´ÐºÐ°"
"ÐšÐ°Ðº ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ñ†ÐµÐ½Ð°?","Ð¦ÐµÐ½Ð° Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¿Ð¾ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸ÑŽ Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸","pricing","Ñ†ÐµÐ½Ð°,ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ,Ñ‚Ð°Ñ€Ð¸Ñ„"
```

#### Ð”Ð»Ñ JSON:
```json
{
  "ride_status": [
    {
      "question": "Ð“Ð´Ðµ Ð¼Ð¾Ð¹ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ?",
      "answer": "Ð’Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ ÐµÐ´ÐµÑ‚ Ðº Ð²Ð°Ð¼, Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ 5 Ð¼Ð¸Ð½ÑƒÑ‚",
      "keywords": ["Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ", "ÑÑ‚Ð°Ñ‚ÑƒÑ", "Ð¿Ð¾ÐµÐ·Ð´ÐºÐ°"]
    }
  ],
  "pricing": [
    {
      "question": "ÐšÐ°Ðº ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ñ†ÐµÐ½Ð°?",
      "answer": "Ð¦ÐµÐ½Ð° Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¿Ð¾ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸ÑŽ Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸",
      "keywords": ["Ñ†ÐµÐ½Ð°", "ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ", "Ñ‚Ð°Ñ€Ð¸Ñ„"]
    }
  ]
}
```

### 3. **Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ APARU**

#### ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ main.py:
```python
# Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚
from enhanced_llm_client import enhanced_llm_client

# Ð’ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ chat() Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼:
# prompt = llm_client.create_taxi_context_prompt(processed_text, intent, final_locale)
# response_text = llm_client.generate_response(prompt)

# ÐÐ°:
prompt = enhanced_llm_client.create_taxi_context_prompt(processed_text, intent, final_locale)
response_text = enhanced_llm_client.generate_response(prompt)
```

#### Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ:
```python
# Ð’ Ð½Ð°Ñ‡Ð°Ð»Ðµ main.py
if enhanced_llm_client.load_knowledge_base():
    logger.info("âœ… Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
else:
    logger.warning("âš ï¸ Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ fallback")
```

## ðŸ”§ Fine-tuning Ð¿Ð¾Ð´Ñ…Ð¾Ð´

### 1. **ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ**

```python
# Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
kb.generate_training_data('training_data.json')
```

### 2. **ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ollama**

```bash
# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Modelfile
cat > Modelfile << EOF
FROM llama2:7b

SYSTEM "Ð¢Ñ‹ - Ð˜Ð˜-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ ÑÐ»ÑƒÐ¶Ð±Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ Ñ‚Ð°ÐºÑÐ¸-ÑÐµÑ€Ð²Ð¸ÑÐ°. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ."

PARAMETER temperature 0.7
PARAMETER top_p 0.9
EOF

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
ollama create taxi-support -f Modelfile

# Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼
ollama run taxi-support "Ð“Ð´Ðµ Ð¼Ð¾Ð¹ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ?"
```

### 3. **ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Transformers**

```python
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer
import torch

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
model_name = "microsoft/DialoGPT-medium"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
def prepare_data(training_data):
    inputs = []
    for item in training_data:
        text = f"Ð’Ð¾Ð¿Ñ€Ð¾Ñ: {item['question']}\nÐžÑ‚Ð²ÐµÑ‚: {item['answer']}"
        inputs.append(text)
    return inputs

# ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼
training_args = TrainingArguments(
    output_dir='./taxi-support-model',
    num_train_epochs=3,
    per_device_train_batch_size=4,
    save_steps=1000,
    save_total_limit=2,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=prepare_data(training_data),
)

trainer.train()
```

## ðŸ“Š Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¾Ð²

| ÐŸÐ¾Ð´Ñ…Ð¾Ð´ | Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ | Ð ÐµÑÑƒÑ€ÑÑ‹ | ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ | ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ |
|--------|------------|---------|------------|----------|
| RAG | ÐÐ¸Ð·ÐºÐ°Ñ | ÐÐ¸Ð·ÐºÐ¸Ðµ | Ð›ÐµÐ³ÐºÐ¾ | Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ |
| Fine-tuning | Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ | Ð’Ñ‹ÑÐ¾ÐºÐ¸Ðµ | Ð¡Ð»Ð¾Ð¶Ð½Ð¾ | ÐžÑ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ðµ |
| Prompt Engineering | ÐžÑ‡ÐµÐ½ÑŒ Ð½Ð¸Ð·ÐºÐ°Ñ | ÐžÑ‡ÐµÐ½ÑŒ Ð½Ð¸Ð·ÐºÐ¸Ðµ | ÐžÑ‡ÐµÐ½ÑŒ Ð»ÐµÐ³ÐºÐ¾ | Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ |

## ðŸŽ¯ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸

### **Ð”Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ð°Ñ€Ñ‚Ð°:**
1. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ RAG Ð¿Ð¾Ð´Ñ…Ð¾Ð´
2. ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒÑ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² CSV/JSON
3. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ `knowledge_base_trainer.py`
4. Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ `enhanced_llm_client.py`

### **Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ð°:**
1. ÐÐ°Ñ‡Ð½Ð¸Ñ‚Ðµ Ñ RAG
2. Ð¡Ð¾Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
3. ÐŸÑ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¸Ñ‚Ðµ Ð½Ð° Fine-tuning

## ðŸ§ª Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ

### **Ð¢ÐµÑÑ‚ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹:**
```python
python3 knowledge_base_trainer.py
```

### **Ð¢ÐµÑÑ‚ enhanced LLM:**
```python
python3 enhanced_llm_client.py
```

### **Ð¢ÐµÑÑ‚ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸:**
```python
python3 main.py
```

## ðŸ“ˆ ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°

### **RAG Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:**
- Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð¸ÑÐºÐ° (precision@k)
- Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
- ÐŸÐ¾ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹

### **LLM Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:**
- ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
- Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ
- ÐŸÐ¾Ð»ÐµÐ·Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹

## ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹

### **Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹:**
```python
# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð±Ð°Ð·Ñƒ
kb = TaxiKnowledgeBase()
kb.load_index('taxi_knowledge_index.pkl')

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
new_data = [
    {
        'question': 'ÐÐ¾Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ',
        'answer': 'ÐÐ¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚',
        'category': 'new_category',
        'keywords': ['Ð½Ð¾Ð²Ñ‹Ð¹', 'Ð²Ð¾Ð¿Ñ€Ð¾Ñ']
    }
]

# ÐŸÐµÑ€ÐµÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¸Ð½Ð´ÐµÐºÑ
kb.knowledge_base.extend(new_data)
kb.build_embeddings_index()
kb.save_index('taxi_knowledge_index.pkl')
```

## ðŸš¨ Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹

### **ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…:**
- ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐ¹Ñ‚Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
- Ð£Ð±Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
- Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼

### **ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ:**
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð»ÐµÐ³ÐºÐ¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²
- ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹
- ÐšÑÑˆÐ¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°

### **Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ:**
- ÐÐµ Ð²ÐºÐ»ÑŽÑ‡Ð°Ð¹Ñ‚Ðµ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
- ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐ¹Ñ‚Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð¿ÐµÑ€ÐµÐ´ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸ÐµÐ¹
- Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
