import json
import re
import os
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from langdetect import detect
from langdetect.lang_detect_exception import LangDetectException

# –ò–º–ø–æ—Ä—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
try:
    from enhanced_morphological_analyzer import enhance_classification_with_morphology, enhanced_analyzer
    MORPHOLOGY_AVAILABLE = True
    print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
except ImportError:
    MORPHOLOGY_AVAILABLE = False
    print("‚ö†Ô∏è –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Taxi Support AI Assistant", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
app.mount("/static", StaticFiles(directory="."), name="static")

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ChatRequest(BaseModel):
    text: str
    user_id: str
    locale: str = "ru"

class ChatResponse(BaseModel):
    response: str
    intent: str
    confidence: float
    source: str  # "kb" –∏–ª–∏ "llm"
    timestamp: str

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
def load_json_file(filename: str) -> Dict[str, Any]:
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.error(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return {}
    except json.JSONDecodeError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≤ {filename}: {e}")
        return {}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
fixtures = load_json_file("fixtures.json")
kb_data = load_json_file("kb.json")

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
def preprocess_text(text: str) -> str:
    """–£–±–∏—Ä–∞–µ—Ç —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã"""
    # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    
    text = emoji_pattern.sub('', text)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'[^\w\s\-.,!?]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
def detect_language(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞"""
    try:
        lang = detect(text)
        if lang in ['ru', 'kk']:
            return 'ru'  # –†—É—Å—Å–∫–∏–π/–∫–∞–∑–∞—Ö—Å–∫–∏–π
        elif lang == 'en':
            return 'en'
        else:
            return 'ru'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä—É—Å—Å–∫–∏–π
    except LangDetectException:
        return 'ru'

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–Ω—Ç–µ–Ω—Ç–æ–≤
def classify_intent(text: str) -> tuple[str, float]:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    text_lower = text.lower()
    
    # FAQ –∏–Ω—Ç–µ–Ω—Ç—ã
    faq_keywords = ['—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ç–∞—Ä–∏—Ñ', '—Ä–∞—Å—á–µ—Ç', '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç', 
                   '–ø—Ä–æ–º–æ–∫–æ–¥', '—Å–∫–∏–¥–∫–∞', '–ø—Ä–æ–º–æ', '–∫–æ–¥', '–≤–≤–µ—Å—Ç–∏',
                   '–æ—Ç–º–µ–Ω–∏—Ç—å', '–æ—Ç–º–µ–Ω–∞', '–æ—Ç–∫–∞–∑',
                   '—Å–≤—è–∑–∞—Ç—å—Å—è', '–ø–æ–∑–≤–æ–Ω–∏—Ç—å', '–≤–æ–¥–∏—Ç–µ–ª—å', '–∫–æ–Ω—Ç–∞–∫—Ç',
                   '–Ω–µ –ø—Ä–∏–µ—Ö–∞–ª', '–æ–ø–æ–∑–¥–∞–ª', '–∂–¥–∞—Ç—å', '–ø—Ä–æ–±–ª–µ–º–∞']
    
    # –°—Ç–∞—Ç—É—Å –ø–æ–µ–∑–¥–∫–∏
    ride_status_keywords = ['–≥–¥–µ –≤–æ–¥–∏—Ç–µ–ª—å', '—Å—Ç–∞—Ç—É—Å', '–ø–æ–µ–∑–¥–∫–∞', '–∑–∞–∫–∞–∑', '–æ–∂–∏–¥–∞–Ω–∏–µ']
    
    # –ß–µ–∫
    receipt_keywords = ['—á–µ–∫', '–∫–≤–∏—Ç–∞–Ω—Ü–∏—è', '–¥–æ–∫—É–º–µ–Ω—Ç', '—Å–ø—Ä–∞–≤–∫–∞']
    
    # –ö–∞—Ä—Ç—ã
    cards_keywords = ['–∫–∞—Ä—Ç–∞', '–∫–∞—Ä—Ç—ã', '–æ—Å–Ω–æ–≤–Ω–∞—è', '–ø–ª–∞—Ç–µ–∂', '–æ–ø–ª–∞—Ç–∞']
    
    # –ñ–∞–ª–æ–±—ã
    complaint_keywords = ['—Å–ø–∏—Å–∞–ª–∏ –¥–≤–∞–∂–¥—ã', '–¥–≤–æ–π–Ω–æ–µ —Å–ø–∏—Å–∞–Ω–∏–µ', '–∂–∞–ª–æ–±–∞', '–ø—Ä–æ–±–ª–µ–º–∞', '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ']
    
    # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    faq_score = sum(1 for keyword in faq_keywords if keyword in text_lower)
    ride_score = sum(1 for keyword in ride_status_keywords if keyword in text_lower)
    receipt_score = sum(1 for keyword in receipt_keywords if keyword in text_lower)
    cards_score = sum(1 for keyword in cards_keywords if keyword in text_lower)
    complaint_score = sum(1 for keyword in complaint_keywords if keyword in text_lower)
    
    scores = {
        'faq': faq_score,
        'ride_status': ride_score,
        'receipt': receipt_score,
        'cards': cards_score,
        'complaint': complaint_score
    }
    
    max_intent = max(scores, key=scores.get)
    max_score = scores[max_intent]
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —á–µ—Ç–∫–æ–≥–æ –∏–Ω—Ç–µ–Ω—Ç–∞, —Å—á–∏—Ç–∞–µ–º FAQ
    if max_score == 0:
        return 'faq', 0.5
    
    confidence = min(max_score / 3.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ 1.0
    return max_intent, confidence

# –ú–æ–∫–∏ –¥–ª—è —Ç–∞–∫—Å–∏
def get_ride_status(user_id: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –ø–æ–µ–∑–¥–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_rides = fixtures.get("rides", {}).get(user_id, {})
    if not user_rides:
        return {"status": "no_rides", "message": "–£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫"}
    
    return user_rides

def send_receipt(user_id: str) -> Dict[str, Any]:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —á–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
    user_receipts = fixtures.get("receipts", {}).get(user_id, [])
    if not user_receipts:
        return {"status": "no_receipts", "message": "–£ –≤–∞—Å –Ω–µ—Ç —á–µ–∫–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"}
    
    latest_receipt = user_receipts[-1]
    return {
        "status": "sent",
        "receipt": latest_receipt,
        "message": f"–ß–µ–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ email. –°—É–º–º–∞: {latest_receipt['amount']} —Ç–µ–Ω–≥–µ"
    }

def list_cards(user_id: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞—Ä—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_cards = fixtures.get("cards", {}).get(user_id, [])
    if not user_cards:
        return {"status": "no_cards", "message": "–£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–∞—Ä—Ç"}
    
    return {"status": "success", "cards": user_cards}

def escalate_to_human(user_id: str, description: str) -> Dict[str, Any]:
    """–≠—Å–∫–∞–ª–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É"""
    tickets = fixtures.get("tickets", {})
    next_id = tickets.get("next_id", 1001)
    
    new_ticket = {
        "ticket_id": f"TKT_{next_id}",
        "user_id": user_id,
        "subject": "–≠—Å–∫–∞–ª–∞—Ü–∏—è –æ—Ç –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞",
        "description": description,
        "status": "open",
        "created_at": datetime.now().isoformat(),
        "priority": "medium"
    }
    
    tickets["tickets"].append(new_ticket)
    tickets["next_id"] = next_id + 1
    
    return {
        "status": "escalated",
        "ticket_id": new_ticket["ticket_id"],
        "message": f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø–µ—Ä–µ–¥–∞–Ω –æ–ø–µ—Ä–∞—Ç–æ—Ä—É. –ù–æ–º–µ—Ä —Ç–∏–∫–µ—Ç–∞: {new_ticket['ticket_id']}"
    }

# –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤ FAQ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º
def search_faq(text: str) -> Optional[Dict[str, Any]]:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π FAQ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    if not text or not kb_data:
        return None
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    if MORPHOLOGY_AVAILABLE:
        try:
            result = enhance_classification_with_morphology(text, kb_data)
            confidence = result.get('confidence', 0)
            logger.info(f"üîç –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: confidence={confidence:.2f}, intent={result.get('intent', 'unknown')}")
            
            # –ü–æ–Ω–∏–∑–∏–ª–∏ –ø–æ—Ä–æ–≥ –¥–æ –º–∏–Ω–∏–º—É–º–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            if result.get('matched_item') and confidence > 0.05:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
                logger.info(f"‚úÖ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞–π–¥–µ–Ω: {confidence:.2f}")
                return result['matched_item']
            elif result.get('matched_item'):
                logger.info(f"‚ö†Ô∏è –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞–π–¥–µ–Ω, –Ω–æ –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
    else:
        logger.warning("‚ö†Ô∏è –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫")
    
    # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –ø–æ–∏—Å–∫—É
    faq_items = kb_data.get("faq", [])
    text_lower = text.lower()
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–µ–Ω–≥–æ–≤—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
    slang_replacements = {
        '—á–µ': '—á—Ç–æ',
        '—Ç–∞–º': '',
        '–ø–æ': '',
        '–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç': '–∫–∞–∫',
        '—Ä–∞–±–æ—Ç–∞–µ—Ç': '—Ä–∞–±–æ—Ç–∞'
    }
    
    processed_text = text_lower
    for slang, replacement in slang_replacements.items():
        processed_text = processed_text.replace(slang, replacement)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    processed_text = ' '.join(processed_text.split())
    
    best_match = None
    best_score = 0
    
    for item in faq_items:
        score = 0
        
        # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π, –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
        keywords = item.get("keywords", [])
        keyword_score = sum(1 for keyword in keywords if keyword in text_lower or keyword in processed_text)
        
        # –ü–æ–∏—Å–∫ –ø–æ –≤–∞—Ä–∏–∞—Ü–∏—è–º –≤–æ–ø—Ä–æ—Å–æ–≤
        variations = item.get("question_variations", [])
        variation_score = 0
        for variation in variations:
            variation_words = set(variation.lower().split())
            text_words = set(text_lower.split())
            processed_words = set(processed_text.split())
            common_words = len(variation_words.intersection(text_words)) + len(variation_words.intersection(processed_words))
            variation_score += common_words
        
        # –ü–æ–∏—Å–∫ –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É
        main_question = item.get("question", "").lower()
        main_score = sum(1 for word in main_question.split() if word in text_lower or word in processed_text)
        
        # –û–±—â–∏–π –±–∞–ª–ª —Å –≤–µ—Å–∞–º–∏
        score = (
            keyword_score * 2.0 +           # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤–∞–∂–Ω–µ–µ
            variation_score * 0.5 +         # –í–∞—Ä–∏–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤
            main_score * 1.0                # –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ–ø—Ä–æ—Å
        )
        
        if score > best_score:
            best_score = score
            best_match = item
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±–∞–ª–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∏–π
    if best_score >= 1.0:
        logger.info(f"‚úÖ –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –Ω–∞–π–¥–µ–Ω: {best_score:.2f}")
        return best_match
    
    return None

# –û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —á–∞—Ç–∞ —Å –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º"""
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
    processed_text = preprocess_text(request.text)
    if not processed_text:
        raise HTTPException(status_code=400, detail="–ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
    detected_lang = detect_language(processed_text)
    final_locale = request.locale if request.locale in ['ru', 'kz', 'en'] else detected_lang
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–Ω—Ç–µ–Ω—Ç–∞
    intent, confidence = classify_intent(processed_text)
    
    logger.info(f"User: {request.user_id}, Intent: {intent}, Confidence: {confidence}, Locale: {final_locale}")
    
    response_text = ""
    source = "llm"
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –∏–Ω—Ç–µ–Ω—Ç—É
    if intent == "faq":
        faq_result = search_faq(processed_text)
        if faq_result:
            response_text = faq_result["answer"]
            source = "kb"
            confidence = 0.9
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ FAQ, –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM
            prompt = llm_client.create_taxi_context_prompt(processed_text, intent, final_locale)
            response_text = llm_client.generate_response(prompt)
    
    elif intent == "ride_status":
        ride_data = get_ride_status(request.user_id)
        if ride_data.get("status") == "no_rides":
            response_text = "–£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫"
        else:
            driver = ride_data.get("driver", {})
            response_text = f"–í–∞—à–∞ –ø–æ–µ–∑–¥–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ. –í–æ–¥–∏—Ç–µ–ª—å: {driver.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}, –º–∞—à–∏–Ω–∞: {driver.get('car', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}, –Ω–æ–º–µ—Ä: {driver.get('plate', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}. –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è –ø—Ä–∏–±—ã—Ç–∏—è: {ride_data.get('estimated_arrival', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
        source = "kb"
        confidence = 0.95
    
    elif intent == "receipt":
        receipt_data = send_receipt(request.user_id)
        response_text = receipt_data["message"]
        source = "kb"
        confidence = 0.95
    
    elif intent == "cards":
        cards_data = list_cards(request.user_id)
        if cards_data["status"] == "success":
            cards = cards_data["cards"]
            primary_card = next((card for card in cards if card.get("is_primary")), None)
            response_text = f"–í–∞—à–∏ –∫–∞—Ä—Ç—ã: {', '.join([f'{card['type']} ****{card['last_four']}' for card in cards])}. –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ä—Ç–∞: {primary_card['type']} ****{primary_card['last_four'] if primary_card else '–ù–µ –≤—ã–±—Ä–∞–Ω–∞'}"
        else:
            response_text = cards_data["message"]
        source = "kb"
        confidence = 0.95
    
    elif intent == "complaint":
        escalation_data = escalate_to_human(request.user_id, processed_text)
        response_text = escalation_data["message"]
        source = "kb"
        confidence = 0.95
    
    else:
        # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM
        prompt = llm_client.create_taxi_context_prompt(processed_text, intent, final_locale)
        response_text = llm_client.generate_response(prompt)
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logger.info(f"Response: {response_text[:100]}..., Source: {source}, Intent: {intent}, Confidence: {confidence}")
    
    return ChatResponse(
        response=response_text,
        intent=intent,
        confidence=confidence,
        source=source,
        timestamp=datetime.now().isoformat()
    )

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –º–æ–∫–æ–≤
@app.get("/ride-status/{user_id}")
async def get_ride_status_endpoint(user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –ø–æ–µ–∑–¥–∫–∏"""
    return get_ride_status(user_id)

@app.post("/send-receipt/{user_id}")
async def send_receipt_endpoint(user_id: str):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —á–µ–∫"""
    return send_receipt(user_id)

@app.get("/cards/{user_id}")
async def list_cards_endpoint(user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞—Ä—Ç"""
    return list_cards(user_id)

@app.post("/escalate/{user_id}")
async def escalate_endpoint(user_id: str, description: str):
    """–≠—Å–∫–∞–ª–∏—Ä–æ–≤–∞—Ç—å –∫ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É"""
    return escalate_to_human(user_id, description)

@app.get("/webapp")
async def webapp():
    """–û—Ç–¥–∞—á–∞ WebApp –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    return FileResponse("webapp.html")

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
